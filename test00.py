import streamlit as st
import pandas as pd
import spacy
import re
import json
import base64
from io import StringIO
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np

# ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
st.set_page_config(page_title="æˆæ¥­è¨˜éŒ²åˆ†æãƒ„ãƒ¼ãƒ«", layout="wide")
st.title("æˆæ¥­è¨˜éŒ²åˆ†æãƒ„ãƒ¼ãƒ«")
st.markdown("ç™ºè¨€å†…å®¹ã‚’åˆ†æã—ã€ç‰¹å®šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚’ä»˜ã‘ã¾ã™")

# spaCyãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
@st.cache_resource
def load_nlp_model():
    try:
        return spacy.load("ja_core_news_sm")
    except OSError:
        st.info("æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...")
        spacy.cli.download("ja_core_news_sm")
        return spacy.load("ja_core_news_sm")

nlp = load_nlp_model()

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ¦‚å¿µè¾æ›¸
default_concept_dict = {
    # æ•™ç§‘ãƒ»å˜å…ƒãƒ»æˆæ¥­æ¦‚å¿µ
    "æ•™ç§‘ãƒ»å˜å…ƒãƒ»æˆæ¥­æ¦‚å¿µ": [
        "æ•°", "è¶³ã—ç®—", "å¼•ãç®—", "æ›ã‘ç®—", "å‰²ã‚Šç®—", "æ–¹ç¨‹å¼", "é–¢æ•°", "å›³å½¢", "ç¢ºç‡",
        "ç‰©èª", "æ–‡ç« ", "èª­è§£", "è¡¨ç¾", "æ–‡æ³•", "æ¼¢å­—", "æ–‡å­¦", "è©©",
        "å®Ÿé¨“", "è¦³å¯Ÿ", "ç”Ÿç‰©", "åŒ–å­¦", "ç‰©ç†", "åœ°å­¦", "å…ƒç´ ", "åå¿œ", "ã‚¨ãƒãƒ«ã‚®ãƒ¼",
        "æ­´å²", "åœ°ç†", "æ”¿æ²»", "çµŒæ¸ˆ", "æ–‡åŒ–", "ç¤¾ä¼š", "å›½éš›", "ç’°å¢ƒ",
        "å˜å…ƒ", "æˆæ¥­", "å­¦ç¿’", "æ•™æ", "ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ "
    ],
    
    # ç¤¾ä¼šçš„æ¦‚å¿µ
    "ç¤¾ä¼šçš„æ¦‚å¿µ": [
        "é“å¾³", "æ­£ç¾©", "æ¨©åˆ©", "è²¬ä»»", "å¹³ç­‰", "è‡ªç”±", "å°Šé‡", "å”åŠ›", "å…±ç”Ÿ",
        "å¤šæ§˜æ€§", "æŒç¶šå¯èƒ½æ€§", "æ°‘ä¸»ä¸»ç¾©", "å¸‚æ°‘æ€§", "ã‚°ãƒ­ãƒ¼ãƒãƒ«", "åœ°åŸŸ", "ä¼çµ±",
        "å¯¾è©±", "è­°è«–", "ç™ºè¡¨", "å”åŠ›", "ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯", "æ„è¦‹", "åˆæ„å½¢æˆ"
    ],
    
    # æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹
    "æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹": [
        "è€ƒãˆ", "ã‚¢ã‚¤ãƒ‡ã‚¢", "ä»®èª¬", "äºˆæƒ³", "æ¨æ¸¬", "åˆ†æ", "è©•ä¾¡", "åˆ¤æ–­",
        "å‰µé€ ", "æ‰¹åˆ¤çš„æ€è€ƒ", "å•é¡Œè§£æ±º", "ãƒ¡ã‚¿èªçŸ¥", "æŒ¯ã‚Šè¿”ã‚Š", "è¨ˆç”»"
    ]
}

# æ¦‚å¿µè¾æ›¸ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦åˆæœŸåŒ–
concept_dict = default_concept_dict.copy()

# å…·ä½“ä¾‹ã‚’ç¤ºã™è¡¨ç¾ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ‹¡å¼µç‰ˆï¼‰
example_patterns = [
    # æ˜ç¤ºçš„ãªä¾‹ç¤ºè¡¨ç¾
    r"ä¾‹ãˆã°[ã€,]", r"ãŸã¨ãˆã°[ã€,]", r"å…·ä½“çš„ã«ã¯", r"å…·ä½“ä¾‹", r"äº‹ä¾‹", r"å®Ÿä¾‹", 
    # æ™‚é–“ã‚„å ´æ‰€ã®å…·ä½“çš„è¡¨ç¾
    r"\d+æœˆ\d+æ—¥", r"æ˜¨æ—¥", r"å…ˆæ—¥", r"å…ˆé€±", r"ä»Šæ—¥", r"æ˜æ—¥", r"åˆå‰", r"åˆå¾Œ", 
    r"ã€œæ™‚", r"ã€œåˆ†", r"ã€œå¹´", r"ã€œæœˆ", r"ã€œæ—¥",
    # äººç‰©ã‚„æ‰€æœ‰ç‰©ã®è¡¨ç¾
    r"ã€œã•ã‚“ã¯", r"ã€œãã‚“ã¯", r"ã€œã¡ã‚ƒã‚“ã¯", r"ç§ã¯", r"åƒ•ã¯", r"ã‚ãŸã—ã¯", r"ã¼ãã¯", 
    r"ç§ã®", r"åƒ•ã®", r"ã‚ãŸã—ã®", r"ã¼ãã®", r"æŒã£ã¦ã„ã‚‹", r"è²·ã£ãŸ", r"ã‚‚ã‚‰ã£ãŸ",
    # å ´æ‰€ã‚„åº—èˆ—ã®è¡¨ç¾
    r"ã€œåº—", r"ã€œå±‹", r"ã€œé¤¨", r"ã€œåœ’", r"ã€œå…¬åœ’", r"ã€œå­¦æ ¡", r"ã€œé§…", r"ã€œå¸‚", r"ã€œçœŒ", 
    r"ã€œç”º", r"ã€œæ‘", r"ã€œåœ°åŒº", r"ã€œã‚»ãƒ³ã‚¿ãƒ¼",
    # æ•°é‡è¡¨ç¾
    r"\d+å€‹", r"\d+å††", r"\d+äºº", r"\d+åŒ¹", r"\d+å°", r"\d+æœ¬", r"\d+å†Š", r"\d+å›",
    # çµŒé¨“è¡¨ç¾
    r"è¡Œã£ãŸ", r"è¦‹ãŸ", r"èã„ãŸ", r"æ„Ÿã˜ãŸ", r"ä½“é¨“", r"çµŒé¨“", r"ã‚„ã£ã¦ã¿ãŸ", r"è©¦ã—ãŸ"
]

# ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»æ€ã„ãƒ»æ§‹æƒ³ã‚’ç¤ºã™è¡¨ç¾ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ‹¡å¼µç‰ˆï¼‰
idea_patterns = [
    # æ€è€ƒè¡¨ç¾
    r"æ€ã„ã¾ã™", r"è€ƒãˆã¾ã™", r"æ„Ÿã˜ã¾ã™", r"ã ã¨æ€ã†", r"ã§ã¯ãªã„ã‹", r"ã‹ã‚‚ã—ã‚Œãªã„", 
    r"ã ã‚ã†", r"ã§ã—ã‚‡ã†", r"ã‚ˆã†ã ", r"ã¿ãŸã„ã ", r"ã‚‰ã—ã„", r"ã£ã½ã„",
    # é¡˜æœ›ãƒ»å¸Œæœ›è¡¨ç¾
    r"ã—ãŸã„", r"æ¬²ã—ã„", r"å¸Œæœ›", r"é¡˜ã„", r"å¤¢", r"ç›®æ¨™", r"ç†æƒ³", r"æœŸå¾…",
    # ææ¡ˆãƒ»ã‚¢ã‚¤ãƒ‡ã‚¢è¡¨ç¾
    r"ã‚¢ã‚¤ãƒ‡ã‚¢", r"ææ¡ˆ", r"æ¡ˆ", r"æ–¹æ³•", r"ã‚„ã‚Šæ–¹", r"å·¥å¤«", r"æ”¹å–„", r"è§£æ±ºç­–",
    # æ„Ÿæƒ…è¡¨ç¾
    r"å¬‰ã—ã„", r"æ‚²ã—ã„", r"æ¥½ã—ã„", r"é¢ç™½ã„", r"æ€–ã„", r"ä¸å®‰", r"å¿ƒé…", r"å®‰å¿ƒ",
    # æ„è¦‹è¡¨ç¾
    r"æ„è¦‹", r"è€ƒãˆ", r"è¦‹è§£", r"ç«‹å ´", r"è¦–ç‚¹", r"è¦³ç‚¹", r"ä¸»å¼µ", r"è³›æˆ", r"åå¯¾",
    # ä»®å®šè¡¨ç¾
    r"ã‚‚ã—", r"ä»®ã«", r"ãŸã‚‰", r"ã‚Œã°", r"ãªã‚‰", r"ã¨ã™ã‚Œã°", r"ã¨ä»®å®šã™ã‚‹ã¨"
]

def parse_concept_dict_file(file_content):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¦‚å¿µè¾æ›¸ã‚’è§£æã™ã‚‹"""
    concept_dict = {}
    current_category = None
    
    for line in file_content.split('\n'):
        line = line.strip()
        if not line or line.startswith('#'):  # ç©ºè¡Œã¾ãŸã¯ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
            continue
        
        if line.startswith('[') and line.endswith(']'):
            # ã‚«ãƒ†ã‚´ãƒªè¡Œ
            current_category = line[1:-1].strip()
            concept_dict[current_category] = []
        elif current_category is not None:
            # ç”¨èªè¡Œ
            terms = [term.strip() for term in line.split(',')]
            concept_dict[current_category].extend([term for term in terms if term])
    
    return concept_dict

def analyze_text_with_context(text):
    """æ–‡è„ˆã‚’è€ƒæ…®ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€é©åˆ‡ãªãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚’ä»˜ã‘ã‚‹"""
    doc = nlp(text)
    
    # æ–‡ç¯€ã”ã¨ã®åˆ†æçµæœã‚’ä¿å­˜
    segments = []
    
    # æ–‡ã‚’åˆ†å‰²ã—ã¦å‡¦ç†
    for sent in doc.sents:
        sent_text = sent.text
        bracket_applied = False
        
        # å…·ä½“ä¾‹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
        for pattern in example_patterns:
            if re.search(pattern, sent_text):
                sent_text = f"[{sent_text}]"
                bracket_applied = True
                break
        
        if not bracket_applied:
            # æ¦‚å¿µè¾æ›¸ã‚’ä½¿ç”¨ã—ã¦æ¦‚å¿µã‚’æ¤œå‡º
            for category, terms in concept_dict.items():
                for term in terms:
                    if term in sent_text:
                        sent_text = f"ï¼ˆ{sent_text}ï¼‰"
                        bracket_applied = True
                        break
                if bracket_applied:
                    break
        
        if not bracket_applied:
            # ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»æ€ã„ãƒ»æ§‹æƒ³ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
            for pattern in idea_patterns:
                if re.search(pattern, sent_text):
                    sent_text = f"ã€ˆ{sent_text}ã€‰"
                    bracket_applied = True
                    break
        
        segments.append(sent_text)
    
    # æ–‡è„ˆåˆ†æï¼ˆéš£æ¥ã™ã‚‹æ–‡ã®é–¢ä¿‚ã‚’è€ƒæ…®ï¼‰
    # ä¾‹ï¼šã€Œç§ã¯è€ƒãˆã¾ã—ãŸã€ã®å¾Œã«ç¶šãæ–‡ã¯ã€ã‚¢ã‚¤ãƒ‡ã‚¢ã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„
    result = []
    idea_context = False
    
    for i, segment in enumerate(segments):
        if i > 0 and idea_context and not (segment.startswith("[") or segment.startswith("ï¼ˆ") or segment.startswith("ã€ˆ")):
            # å‰ã®æ–‡ãŒã‚¢ã‚¤ãƒ‡ã‚¢æ–‡è„ˆã§ã€ç¾åœ¨ã®æ–‡ã«ãƒ–ãƒ©ã‚±ãƒƒãƒˆãŒãªã„å ´åˆ
            segment = f"ã€ˆ{segment}ã€‰"
        
        # ã‚¢ã‚¤ãƒ‡ã‚¢æ–‡è„ˆã®æ›´æ–°
        idea_context = any(re.search(pattern, segment) for pattern in [r"è€ƒãˆ", r"æ€ã„", r"ã‚¢ã‚¤ãƒ‡ã‚¢", r"ææ¡ˆ"])
        
        result.append(segment)
    
    return "".join(result)

def decompose_utterance_by_brackets(text):
    """ç™ºè¨€ã‚’ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥ã«åˆ†è§£ã™ã‚‹"""
    # ãƒ–ãƒ©ã‚±ãƒƒãƒˆã®ç¨®é¡ã‚’å®šç¾©
    bracket_types = {
        'example': {'start': '[', 'end': ']', 'name': 'ä¾‹ç¤º'},
        'concept': {'start': 'ï¼ˆ', 'end': 'ï¼‰', 'name': 'æ¦‚å¿µ'},
        'idea': {'start': 'ã€ˆ', 'end': 'ã€‰', 'name': 'æ§‹æƒ³'},
        'other': {'name': 'ãã®ä»–'}
    }
    
    result = {
        'example': [],
        'concept': [],
        'idea': [],
        'other': []
    }
    
    # å„ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡ã®å†…å®¹ã‚’æŠ½å‡º
    for bracket_type, info in bracket_types.items():
        if bracket_type == 'other':
            continue
            
        start_char = info['start']
        end_char = info['end']
        
        # æ­£è¦è¡¨ç¾ã§ãƒ–ãƒ©ã‚±ãƒƒãƒˆå†…å®¹ã‚’æŠ½å‡º
        pattern = f"\\{start_char}([^\\{start_char}\\{end_char}]*?)\\{end_char}"
        matches = re.findall(pattern, text)
        result[bracket_type] = matches
    
    # ãã®ä»–ã®éƒ¨åˆ†ï¼ˆãƒ–ãƒ©ã‚±ãƒƒãƒˆã§å›²ã¾ã‚Œã¦ã„ãªã„éƒ¨åˆ†ï¼‰ã‚’æŠ½å‡º
    # ã™ã¹ã¦ã®ãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚’é™¤å»ã—ãŸæ®‹ã‚Šã®éƒ¨åˆ†
    other_text = text
    for bracket_type, info in bracket_types.items():
        if bracket_type == 'other':
            continue
        start_char = info['start']
        end_char = info['end']
        pattern = f"\\{start_char}[^\\{start_char}\\{end_char}]*?\\{end_char}"
        other_text = re.sub(pattern, '', other_text)
    
    # ç©ºç™½ã‚„å¥èª­ç‚¹ã®ã¿ã®å ´åˆã¯é™¤å¤–
    other_text = other_text.strip()
    if other_text and not re.match(r'^[ã€ã€‚\s]*$', other_text):
        result['other'] = [other_text]
    else:
        result['other'] = []
    
    return result

def create_matrix_data(df):
    """ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹"""
    matrix_data = []
    
    for idx, row in df.iterrows():
        utterance_id = row['ç™ºè¨€ç•ªå·']
        speaker = row['ç™ºè¨€è€…']
        analyzed_text = row['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹']
        
        # ãƒ–ãƒ©ã‚±ãƒƒãƒˆåˆ¥ã«åˆ†è§£
        decomposed = decompose_utterance_by_brackets(analyzed_text)
        
        # å„ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡ã«ã¤ã„ã¦
        for bracket_type, contents in decomposed.items():
            if contents:  # å†…å®¹ãŒã‚ã‚‹å ´åˆã®ã¿
                count = len(contents)
                matrix_data.append({
                    'ç™ºè¨€ç•ªå·': utterance_id,
                    'ç™ºè¨€è€…': speaker,
                    'ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡': bracket_type,
                    'å‡ºç¾å›æ•°': count,
                    'å†…å®¹': contents,
                    'ç™ºè¨€ãƒ©ãƒ™ãƒ«': f"ç™ºè¨€{utterance_id}: {speaker}"
                })
    
    return pd.DataFrame(matrix_data)

def create_matrix_visualization(matrix_df, selected_speakers=None):
    """ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ã‚’ä½œæˆã™ã‚‹"""
    if matrix_df.empty:
        return None
    
    # ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡ã®æ—¥æœ¬èªåãƒãƒƒãƒ”ãƒ³ã‚°
    bracket_names = {
        'example': 'ä¾‹ç¤º',
        'concept': 'æ¦‚å¿µ', 
        'idea': 'æ§‹æƒ³',
        'other': 'ãã®ä»–'
    }
    
    # ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡ã‚’æ—¥æœ¬èªåã«å¤‰æ›
    matrix_df['ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡_æ—¥æœ¬èª'] = matrix_df['ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡'].map(bracket_names)
    
    # ç™ºè¨€è€…ã®è‰²ã‚’è¨­å®š
    unique_speakers = matrix_df['ç™ºè¨€è€…'].unique()
    colors = px.colors.qualitative.Set3[:len(unique_speakers)]
    speaker_colors = dict(zip(unique_speakers, colors))
    
    # é¸æŠã•ã‚ŒãŸç™ºè¨€è€…ã«åŸºã¥ã„ã¦é€æ˜åº¦ã‚’è¨­å®š
    if selected_speakers:
        matrix_df['é€æ˜åº¦'] = matrix_df['ç™ºè¨€è€…'].apply(
            lambda x: 1.0 if x in selected_speakers else 0.3
        )
        matrix_df['ãƒãƒ¼ã‚«ãƒ¼'] = matrix_df['ç™ºè¨€è€…'].apply(
            lambda x: 'ğŸ”¸' if x in selected_speakers else 'âšª'
        )
    else:
        matrix_df['é€æ˜åº¦'] = 1.0
        matrix_df['ãƒãƒ¼ã‚«ãƒ¼'] = 'ğŸ”¸'
    
    # æ•£å¸ƒå›³ã‚’ä½œæˆ
    fig = go.Figure()
    
    for speaker in unique_speakers:
        speaker_data = matrix_df[matrix_df['ç™ºè¨€è€…'] == speaker]
        
        # é¸æŠçŠ¶æ…‹ã«å¿œã˜ã¦é€æ˜åº¦ã‚’è¨­å®š
        if selected_speakers:
            opacity = 1.0 if speaker in selected_speakers else 0.3
            line_width = 2 if speaker in selected_speakers else 0
        else:
            opacity = 0.8
            line_width = 1
        
        fig.add_trace(go.Scatter(
            x=speaker_data['ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡_æ—¥æœ¬èª'],
            y=speaker_data['ç™ºè¨€ãƒ©ãƒ™ãƒ«'],
            mode='markers',
            marker=dict(
                size=speaker_data['å‡ºç¾å›æ•°'] * 10 + 5,  # ã‚µã‚¤ã‚ºã‚’å‡ºç¾å›æ•°ã«æ¯”ä¾‹
                color=speaker_colors[speaker],
                opacity=opacity,
                line=dict(width=line_width, color='black')
            ),
            name=speaker,
            text=speaker_data.apply(lambda row: 
                f"ç™ºè¨€è€…: {row['ç™ºè¨€è€…']}<br>" +
                f"ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡: {row['ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡_æ—¥æœ¬èª']}<br>" +
                f"å‡ºç¾å›æ•°: {row['å‡ºç¾å›æ•°']}<br>" +
                f"å†…å®¹: {', '.join(row['å†…å®¹'][:3])}{'...' if len(row['å†…å®¹']) > 3 else ''}", 
                axis=1
            ),
            hovertemplate='%{text}<extra></extra>'
        ))
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
    fig.update_layout(
        title="ç™ºè¨€ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–",
        xaxis_title="ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡",
        yaxis_title="ç™ºè¨€ï¼ˆæ™‚ç³»åˆ—é †ï¼‰",
        height=max(600, len(matrix_df['ç™ºè¨€ãƒ©ãƒ™ãƒ«'].unique()) * 30),
        showlegend=True,
        hovermode='closest'
    )
    
    # Yè»¸ã‚’é€†é †ã«ã—ã¦æ™‚ç³»åˆ—é †ã«è¡¨ç¤º
    fig.update_yaxis(autorange="reversed")
    
    return fig

def process_csv(df):
    """CSVãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã€ç™ºè¨€å†…å®¹ã«ãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚’ä»˜ã‘ã‚‹"""
    if 'ç™ºè¨€å†…å®¹' not in df.columns:
        st.error("CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã€Œç™ºè¨€å†…å®¹ã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None
    
    # ç™ºè¨€å†…å®¹ã‚’åˆ†æ
    df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] = df['ç™ºè¨€å†…å®¹'].apply(analyze_text_with_context)
    
    return df

def get_csv_download_link(df, filename="analyzed_data.csv"):
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’CSVã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ"""
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">åˆ†æçµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
    return href

def get_dict_download_link(dict_data, filename="concept_dictionary.txt"):
    """æ¦‚å¿µè¾æ›¸ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ"""
    content = ""
    for category, terms in dict_data.items():
        content += f"[{category}]\n"
        # 10å€‹ã”ã¨ã«æ”¹è¡Œã—ã¦è¦‹ã‚„ã™ãã™ã‚‹
        for i in range(0, len(terms), 10):
            content += ", ".join(terms[i:i+10]) + "\n"
        content += "\n"
    
    b64 = base64.b64encode(content.encode()).decode()
    href = f'<a href="data:file/txt;base64,{b64}" download="{filename}">æ¦‚å¿µè¾æ›¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
    return href

def get_pattern_download_link(filename="patterns.txt"):
    """ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ"""
    content = "# å…·ä½“ä¾‹ãƒ‘ã‚¿ãƒ¼ãƒ³\n"
    for pattern in example_patterns:
        content += pattern + "\n"
    
    content += "\n# ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»æ€ã„ãƒ»æ§‹æƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³\n"
    for pattern in idea_patterns:
        content += pattern + "\n"
    
    b64 = base64.b64encode(content.encode()).decode()
    href = f'<a href="data:file/txt;base64,{b64}" download="{filename}">ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
    return href

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š
st.sidebar.header("è¨­å®š")

# æ¦‚å¿µè¾æ›¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
st.sidebar.subheader("æ¦‚å¿µè¾æ›¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
dict_file = st.sidebar.file_uploader("æ¦‚å¿µè¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["txt"])

if dict_file is not None:
    try:
        dict_content = dict_file.getvalue().decode("utf-8")
        uploaded_dict = parse_concept_dict_file(dict_content)
        if uploaded_dict:
            concept_dict = uploaded_dict
            st.sidebar.success("æ¦‚å¿µè¾æ›¸ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
        else:
            st.sidebar.warning("æœ‰åŠ¹ãªæ¦‚å¿µè¾æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¾æ›¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    except Exception as e:
        st.sidebar.error(f"è¾æ›¸ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.sidebar.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¾æ›¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

# æ¦‚å¿µè¾æ›¸ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ã‚’è¡¨ç¤º
st.sidebar.subheader("æ¦‚å¿µè¾æ›¸ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹")
dict_format_example = """
# æ¦‚å¿µè¾æ›¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹
[æ•™ç§‘ãƒ»å˜å…ƒãƒ»æˆæ¥­æ¦‚å¿µ]
æ•°å­¦, ç®—æ•°, å›½èª, ç†ç§‘, ç¤¾ä¼š
æ–¹ç¨‹å¼, é–¢æ•°, å›³å½¢, ç¢ºç‡, çµ±è¨ˆ

[ç¤¾ä¼šçš„æ¦‚å¿µ]
æ°‘ä¸»ä¸»ç¾©, äººæ¨©, ç’°å¢ƒ, æŒç¶šå¯èƒ½æ€§
å¤šæ§˜æ€§, å…¬æ­£, å¹³ç­‰, è‡ªç”±, è²¬ä»»

# ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã¯#ã§å§‹ã‚ã¾ã™
"""
st.sidebar.code(dict_format_example, language="text")

# ç¾åœ¨ã®æ¦‚å¿µè¾æ›¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
if st.sidebar.button("ç¾åœ¨ã®æ¦‚å¿µè¾æ›¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
    st.sidebar.markdown(get_dict_download_link(concept_dict), unsafe_allow_html=True)

# ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
st.sidebar.subheader("ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
pattern_file = st.sidebar.file_uploader("ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["txt"])

if pattern_file is not None:
    try:
        pattern_content = pattern_file.getvalue().decode("utf-8")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’è§£æ
        new_example_patterns = []
        new_idea_patterns = []
        current_section = None
        
        for line in pattern_content.split('\n'):
            line = line.strip()
            if not line or line.startswith('#'):
                if "å…·ä½“ä¾‹" in line:
                    current_section = "example"
                elif "ã‚¢ã‚¤ãƒ‡ã‚¢" in line or "æ€ã„" in line or "æ§‹æƒ³" in line:
                    current_section = "idea"
                continue
            
            if current_section == "example":
                new_example_patterns.append(line)
            elif current_section == "idea":
                new_idea_patterns.append(line)
        
        if new_example_patterns:
            example_patterns = new_example_patterns
        if new_idea_patterns:
            idea_patterns = new_idea_patterns
            
        st.sidebar.success("ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    except Exception as e:
        st.sidebar.error(f"ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ç¾åœ¨ã®ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
if st.sidebar.button("ç¾åœ¨ã®ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
    st.sidebar.markdown(get_pattern_download_link(), unsafe_allow_html=True)

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
st.sidebar.subheader("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å½¢å¼")
sample_data = pd.DataFrame({
    'ç™ºè¨€ç•ªå·': [1, 2, 3, 4, 5, 6, 7, 8],
    'ç™ºè¨€è€…': ['æ•™å¸«', 'ç”Ÿå¾’A', 'ç”Ÿå¾’B', 'ç”Ÿå¾’C', 'æ•™å¸«', 'ç”Ÿå¾’A', 'ç”Ÿå¾’D', 'æ•™å¸«'],
    'ç™ºè¨€å†…å®¹': [
        'ä»Šæ—¥ã¯ä¸‰è§’å½¢ã®é¢ç©ã«ã¤ã„ã¦å­¦ã³ã¾ã—ã‚‡ã†ã€‚',
        'ä¾‹ãˆã°ã€ã“ã®å›³å½¢ã®é¢ç©ã¯ã©ã†ã‚„ã£ã¦æ±‚ã‚ã¾ã™ã‹ï¼Ÿ',
        'åº•è¾ºÃ—é«˜ã•Ã·2ã ã¨æ€ã„ã¾ã™ã€‚',
        'æ˜¨æ—¥ã€ãŠçˆ¶ã•ã‚“ã¨ä¸€ç·’ã«å…¬åœ’ã§ä¸‰è§’å½¢ã®çœ‹æ¿ã‚’è¦‹ã¾ã—ãŸã€‚',
        'ã¿ãªã•ã‚“ã®è€ƒãˆã‚’èã‹ã›ã¦ãã ã•ã„ã€‚',
        'ç§ã¯ã€ã‚‚ã£ã¨ç°¡å˜ãªæ–¹æ³•ãŒã‚ã‚‹ã¨æ€ã„ã¾ã™ã€‚',
        'æ•°å­¦ã¯é¢ç™½ã„ã§ã™ã­ã€‚',
        'ã¨ã¦ã‚‚è‰¯ã„æ„è¦‹ã§ã™ã­ã€‚'
    ]
})
st.sidebar.dataframe(sample_data)

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
use_sample = st.checkbox("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨")

# åˆ†æè¨­å®š
st.sidebar.subheader("åˆ†æè¨­å®š")
show_patterns = st.sidebar.checkbox("ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºè¨­å®šã‚’è¡¨ç¤º")

if show_patterns:
    st.sidebar.subheader("å…·ä½“ä¾‹ãƒ‘ã‚¿ãƒ¼ãƒ³")
    example_patterns_text = st.sidebar.text_area("å…·ä½“ä¾‹ã‚’ç¤ºã™è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ1è¡Œã«1ã¤ï¼‰", 
                                               "\n".join(p for p in example_patterns))
    
    st.sidebar.subheader("ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ‘ã‚¿ãƒ¼ãƒ³")
    idea_patterns_text = st.sidebar.text_area("ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»æ€ã„ãƒ»æ§‹æƒ³ã‚’ç¤ºã™è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ1è¡Œã«1ã¤ï¼‰", 
                                            "\n".join(p for p in idea_patterns))
    
    if st.sidebar.button("ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’æ›´æ–°"):
        example_patterns = [p.strip() for p in example_patterns_text.split("\n") if p.strip()]
        idea_patterns = [p.strip() for p in idea_patterns_text.split("\n") if p.strip()]
        st.sidebar.success("ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")

# åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³
st.sidebar.subheader("åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³")
enable_context_analysis = st.sidebar.checkbox("æ–‡è„ˆåˆ†æã‚’æœ‰åŠ¹ã«ã™ã‚‹", value=True)
bracket_overlap_strategy = st.sidebar.radio(
    "ãƒ–ãƒ©ã‚±ãƒƒãƒˆé‡è¤‡æ™‚ã®æˆ¦ç•¥",
    ["å„ªå…ˆé †ä½ï¼ˆå…·ä½“ä¾‹ > æ¦‚å¿µ > ã‚¢ã‚¤ãƒ‡ã‚¢ï¼‰", "æœ€é•·ä¸€è‡´", "é‡è¤‡ã‚’è¨±å¯ï¼ˆå…¥ã‚Œå­ï¼‰"]
)

# åˆ†æçµæœã®çµ±è¨ˆ
def show_analysis_stats(df):
    if 'analyzed' not in st.session_state:
        st.session_state.analyzed = True
        
        total_utterances = len(df)
        example_count = sum(1 for text in df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if '[' in text)
        concept_count = sum(1 for text in df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if 'ï¼ˆ' in text)
        idea_count = sum(1 for text in df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if 'ã€ˆ' in text)
        
        st.subheader("åˆ†æçµ±è¨ˆ")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ç·ç™ºè¨€æ•°", total_utterances)
        with col2:
            st.metric("å…·ä½“ä¾‹ [ã€€]", example_count, f"{example_count/total_utterances:.1%}")
        with col3:
            st.metric("æ¦‚å¿µ ï¼ˆã€€ï¼‰", concept_count, f"{concept_count/total_utterances:.1%}")
        with col4:
            st.metric("ã‚¢ã‚¤ãƒ‡ã‚¢ ã€ˆã€€ã€‰", idea_count, f"{idea_count/total_utterances:.1%}")
        
        # ç™ºè¨€è€…åˆ¥ã®çµ±è¨ˆ
        if 'ç™ºè¨€è€…' in df.columns:
            st.subheader("ç™ºè¨€è€…åˆ¥ã®åˆ†æ")
            speaker_stats = {}
            
            for speaker in df['ç™ºè¨€è€…'].unique():
                speaker_df = df[df['ç™ºè¨€è€…'] == speaker]
                speaker_total = len(speaker_df)
                speaker_example = sum(1 for text in speaker_df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if '[' in text)
                speaker_concept = sum(1 for text in speaker_df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if 'ï¼ˆ' in text)
                speaker_idea = sum(1 for text in speaker_df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if 'ã€ˆ' in text)
                
                speaker_stats[speaker] = {
                    "ç·ç™ºè¨€æ•°": speaker_total,
                    "å…·ä½“ä¾‹": speaker_example,
                    "æ¦‚å¿µ": speaker_concept,
                    "ã‚¢ã‚¤ãƒ‡ã‚¢": speaker_idea
                }
            
            speaker_df = pd.DataFrame(speaker_stats).T
            st.dataframe(speaker_df)
            
            # ç™ºè¨€è€…åˆ¥ã®ã‚°ãƒ©ãƒ•
            st.subheader("ç™ºè¨€è€…åˆ¥ã®ãƒ–ãƒ©ã‚±ãƒƒãƒˆåˆ†å¸ƒ")
            speaker_chart_data = pd.DataFrame({
                "ç™ºè¨€è€…": list(speaker_stats.keys()) * 3,
                "ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡": ["å…·ä½“ä¾‹"] * len(speaker_stats) + ["æ¦‚å¿µ"] * len(speaker_stats) + ["ã‚¢ã‚¤ãƒ‡ã‚¢"] * len(speaker_stats),
                "ç™ºè¨€æ•°": [stats["å…·ä½“ä¾‹"] for stats in speaker_stats.values()] + 
                         [stats["æ¦‚å¿µ"] for stats in speaker_stats.values()] + 
                         [stats["ã‚¢ã‚¤ãƒ‡ã‚¢"] for stats in speaker_stats.values()]
            })
            
            st.bar_chart(speaker_chart_data, x="ç™ºè¨€è€…", y="ç™ºè¨€æ•°", color="ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡")

# ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–æ©Ÿèƒ½
def show_matrix_visualization(df):
    st.subheader("ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–")
    st.markdown("ç™ºè¨€ã‚’æ™‚ç³»åˆ—é †ã«ä¸¦ã¹ã€ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥ã«åˆ†è§£ã—ã¦è¡¨ç¤ºã—ã¾ã™ã€‚")
    
    # ãƒãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    matrix_df = create_matrix_data(df)
    
    if matrix_df.empty:
        st.warning("ãƒãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # ç™ºè¨€è€…é¸æŠæ©Ÿèƒ½
    st.subheader("ç™ºè¨€è€…é¸æŠ")
    all_speakers = df['ç™ºè¨€è€…'].unique().tolist()
    selected_speakers = st.multiselect(
        "ãƒã‚¤ãƒ©ã‚¤ãƒˆã™ã‚‹ç™ºè¨€è€…ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
        options=all_speakers,
        default=all_speakers,
        help="é¸æŠã•ã‚ŒãŸç™ºè¨€è€…ã®ç™ºè¨€ãŒãƒã‚¤ãƒ©ã‚¤ãƒˆã•ã‚Œã¾ã™"
    )
    
    # ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ã‚’ä½œæˆ
    fig = create_matrix_visualization(matrix_df, selected_speakers)
    
    if fig:
        st.plotly_chart(fig, use_container_width=True)
    
    # ãƒãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°è¡¨ç¤º
    with st.expander("ãƒãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°"):
        st.dataframe(matrix_df)
    
    # ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥ã®çµ±è¨ˆ
    with st.expander("ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥ã®çµ±è¨ˆ"):
        bracket_stats = matrix_df.groupby('ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡')['å‡ºç¾å›æ•°'].sum().reset_index()
        bracket_stats['ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡_æ—¥æœ¬èª'] = bracket_stats['ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡'].map({
            'example': 'ä¾‹ç¤º',
            'concept': 'æ¦‚å¿µ',
            'idea': 'æ§‹æƒ³',
            'other': 'ãã®ä»–'
        })
        
        col1, col2 = st.columns(2)
        with col1:
            st.dataframe(bracket_stats[['ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡_æ—¥æœ¬èª', 'å‡ºç¾å›æ•°']])
        with col2:
            fig_pie = px.pie(bracket_stats, values='å‡ºç¾å›æ•°', names='ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡_æ—¥æœ¬èª', 
                           title="ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥ã®åˆ†å¸ƒ")
            st.plotly_chart(fig_pie, use_container_width=True)
    
    # ç™ºè¨€ã®è©³ç´°åˆ†è§£è¡¨ç¤º
    with st.expander("å„ç™ºè¨€ã®ãƒ–ãƒ©ã‚±ãƒƒãƒˆåˆ†è§£è©³ç´°"):
        for idx, row in df.iterrows():
            st.markdown(f"**ç™ºè¨€ {row['ç™ºè¨€ç•ªå·']} - {row['ç™ºè¨€è€…']}**")
            decomposed = decompose_utterance_by_brackets(row['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'])
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.markdown("**ä¾‹ç¤º [ã€€]**")
                for item in decomposed['example']:
                    st.write(f"â€¢ {item}")
            with col2:
                st.markdown("**æ¦‚å¿µ ï¼ˆã€€ï¼‰**")
                for item in decomposed['concept']:
                    st.write(f"â€¢ {item}")
            with col3:
                st.markdown("**æ§‹æƒ³ ã€ˆã€€ã€‰**")
                for item in decomposed['idea']:
                    st.write(f"â€¢ {item}")
            with col4:
                st.markdown("**ãã®ä»–**")
                for item in decomposed['other']:
                    st.write(f"â€¢ {item}")
            
            st.markdown("---")

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
if uploaded_file is not None:
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    try:
        df = pd.read_csv(uploaded_file)
        st.subheader("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿")
        st.dataframe(df)
        
        analyzed_df = process_csv(df)
        if analyzed_df is not None:
            st.subheader("åˆ†æçµæœ")
            st.dataframe(analyzed_df)
            st.markdown(get_csv_download_link(analyzed_df), unsafe_allow_html=True)
            
            # åˆ†æçµ±è¨ˆã‚’è¡¨ç¤º
            show_analysis_stats(analyzed_df)
            
            # ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ã‚’è¡¨ç¤º
            show_matrix_visualization(analyzed_df)
            
            # è©³ç´°ãªåˆ†æçµæœã®è¡¨ç¤º
            st.subheader("ç™ºè¨€å†…å®¹ã®è©³ç´°åˆ†æ")
            for idx, row in analyzed_df.iterrows():
                with st.expander(f"ç™ºè¨€ {row['ç™ºè¨€ç•ªå·']} - {row['ç™ºè¨€è€…']}"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("**å…ƒã®ç™ºè¨€å†…å®¹:**")
                        st.write(row['ç™ºè¨€å†…å®¹'])
                    with col2:
                        st.markdown("**åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹:**")
                        st.write(row['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'])
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

elif use_sample:
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
    st.subheader("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿")
    st.dataframe(sample_data)
    
    analyzed_df = process_csv(sample_data)
    if analyzed_df is not None:
        st.subheader("åˆ†æçµæœ")
        st.dataframe(analyzed_df)
        st.markdown(get_csv_download_link(analyzed_df, "sample_analyzed_data.csv"), unsafe_allow_html=True)
        
        # åˆ†æçµ±è¨ˆã‚’è¡¨ç¤º
        show_analysis_stats(analyzed_df)
        
        # ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ã‚’è¡¨ç¤º
        show_matrix_visualization(analyzed_df)
        
        # è©³ç´°ãªåˆ†æçµæœã®è¡¨ç¤º
        st.subheader("ç™ºè¨€å†…å®¹ã®è©³ç´°åˆ†æ")
        for idx, row in analyzed_df.iterrows():
            with st.expander(f"ç™ºè¨€ {row['ç™ºè¨€ç•ªå·']} - {row['ç™ºè¨€è€…']}"):
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**å…ƒã®ç™ºè¨€å†…å®¹:**")
                    st.write(row['ç™ºè¨€å†…å®¹'])
                with col2:
                    st.markdown("**åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹:**")
                    st.write(row['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'])
else:
    st.info("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
