import streamlit as st
import pandas as pd
import numpy as np
import spacy
import re
import json
import base64
from io import StringIO
import os
import plotly.express as px
import plotly.graph_objects as go
from collections import defaultdict
import random

# ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
st.set_page_config(page_title="æˆæ¥­è¨˜éŒ²åˆ†æãƒ„ãƒ¼ãƒ«", layout="wide")
st.title("æˆæ¥­è¨˜éŒ²åˆ†æãƒ„ãƒ¼ãƒ«")
st.markdown("ç™ºè¨€å†…å®¹ã‚’åˆ†æã—ã€ç‰¹å®šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚’ä»˜ã‘ã¾ã™")

# spaCyãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
@st.cache_resource
def load_nlp_model():
    try:
        return spacy.load("ja_core_news_sm")
    except OSError:
        st.info("æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...")
        spacy.cli.download("ja_core_news_sm")
        return spacy.load("ja_core_news_sm")

nlp = load_nlp_model()

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ¦‚å¿µè¾æ›¸
default_concept_dict = {
    # æ•™ç§‘ãƒ»å˜å…ƒãƒ»æˆæ¥­æ¦‚å¿µ
    "æ•™ç§‘ãƒ»å˜å…ƒãƒ»æˆæ¥­æ¦‚å¿µ": [
        "æ•°", "è¶³ã—ç®—", "å¼•ãç®—", "æ›ã‘ç®—", "å‰²ã‚Šç®—", "æ–¹ç¨‹å¼", "é–¢æ•°", "å›³å½¢", "ç¢ºç‡",
        "ç‰©èª", "æ–‡ç« ", "èª­è§£", "è¡¨ç¾", "æ–‡æ³•", "æ¼¢å­—", "æ–‡å­¦", "è©©",
        "å®Ÿé¨“", "è¦³å¯Ÿ", "ç”Ÿç‰©", "åŒ–å­¦", "ç‰©ç†", "åœ°å­¦", "å…ƒç´ ", "åå¿œ", "ã‚¨ãƒãƒ«ã‚®ãƒ¼",
        "æ­´å²", "åœ°ç†", "æ”¿æ²»", "çµŒæ¸ˆ", "æ–‡åŒ–", "ç¤¾ä¼š", "å›½éš›", "ç’°å¢ƒ",
        "å˜å…ƒ", "æˆæ¥­", "å­¦ç¿’", "æ•™æ", "ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ "
    ],
    
    # ç¤¾ä¼šçš„æ¦‚å¿µ
    "ç¤¾ä¼šçš„æ¦‚å¿µ": [
        "é“å¾³", "æ­£ç¾©", "æ¨©åˆ©", "è²¬ä»»", "å¹³ç­‰", "è‡ªç”±", "å°Šé‡", "å”åŠ›", "å…±ç”Ÿ",
        "å¤šæ§˜æ€§", "æŒç¶šå¯èƒ½æ€§", "æ°‘ä¸»ä¸»ç¾©", "å¸‚æ°‘æ€§", "ã‚°ãƒ­ãƒ¼ãƒãƒ«", "åœ°åŸŸ", "ä¼çµ±",
        "å¯¾è©±", "è­°è«–", "ç™ºè¡¨", "å”åŠ›", "ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯", "æ„è¦‹", "åˆæ„å½¢æˆ"
    ],
    
    # æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹
    "æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹": [
        "è€ƒãˆ", "ã‚¢ã‚¤ãƒ‡ã‚¢", "ä»®èª¬", "äºˆæƒ³", "æ¨æ¸¬", "åˆ†æ", "è©•ä¾¡", "åˆ¤æ–­",
        "å‰µé€ ", "æ‰¹åˆ¤çš„æ€è€ƒ", "å•é¡Œè§£æ±º", "ãƒ¡ã‚¿èªçŸ¥", "æŒ¯ã‚Šè¿”ã‚Š", "è¨ˆç”»"
    ]
}

# æ¦‚å¿µè¾æ›¸ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦åˆæœŸåŒ–
concept_dict = default_concept_dict.copy()

# å…·ä½“ä¾‹ã‚’ç¤ºã™è¡¨ç¾ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ‹¡å¼µç‰ˆï¼‰
example_patterns = [
    # æ˜ç¤ºçš„ãªä¾‹ç¤ºè¡¨ç¾
    r"ä¾‹ãˆã°[ã€,]", r"ãŸã¨ãˆã°[ã€,]", r"å…·ä½“çš„ã«ã¯", r"å…·ä½“ä¾‹", r"äº‹ä¾‹", r"å®Ÿä¾‹", 
    # æ™‚é–“ã‚„å ´æ‰€ã®å…·ä½“çš„è¡¨ç¾
    r"\d+æœˆ\d+æ—¥", r"æ˜¨æ—¥", r"å…ˆæ—¥", r"å…ˆé€±", r"ä»Šæ—¥", r"æ˜æ—¥", r"åˆå‰", r"åˆå¾Œ", 
    r"ã€œæ™‚", r"ã€œåˆ†", r"ã€œå¹´", r"ã€œæœˆ", r"ã€œæ—¥",
    # äººç‰©ã‚„æ‰€æœ‰ç‰©ã®è¡¨ç¾
    r"ã€œã•ã‚“ã¯", r"ã€œãã‚“ã¯", r"ã€œã¡ã‚ƒã‚“ã¯", r"ç§ã¯", r"åƒ•ã¯", r"ã‚ãŸã—ã¯", r"ã¼ãã¯", 
    r"ç§ã®", r"åƒ•ã®", r"ã‚ãŸã—ã®", r"ã¼ãã®", r"æŒã£ã¦ã„ã‚‹", r"è²·ã£ãŸ", r"ã‚‚ã‚‰ã£ãŸ",
    # å ´æ‰€ã‚„åº—èˆ—ã®è¡¨ç¾
    r"ã€œåº—", r"ã€œå±‹", r"ã€œé¤¨", r"ã€œåœ’", r"ã€œå…¬åœ’", r"ã€œå­¦æ ¡", r"ã€œé§…", r"ã€œå¸‚", r"ã€œçœŒ", 
    r"ã€œç”º", r"ã€œæ‘", r"ã€œåœ°åŒº", r"ã€œã‚»ãƒ³ã‚¿ãƒ¼",
    # æ•°é‡è¡¨ç¾
    r"\d+å€‹", r"\d+å††", r"\d+äºº", r"\d+åŒ¹", r"\d+å°", r"\d+æœ¬", r"\d+å†Š", r"\d+å›",
    # çµŒé¨“è¡¨ç¾
    r"è¡Œã£ãŸ", r"è¦‹ãŸ", r"èã„ãŸ", r"æ„Ÿã˜ãŸ", r"ä½“é¨“", r"çµŒé¨“", r"ã‚„ã£ã¦ã¿ãŸ", r"è©¦ã—ãŸ"
]

# ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»æ€ã„ãƒ»æ§‹æƒ³ã‚’ç¤ºã™è¡¨ç¾ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ‹¡å¼µç‰ˆï¼‰
idea_patterns = [
    # æ€è€ƒè¡¨ç¾
    r"æ€ã„ã¾ã™", r"è€ƒãˆã¾ã™", r"æ„Ÿã˜ã¾ã™", r"ã ã¨æ€ã†", r"ã§ã¯ãªã„ã‹", r"ã‹ã‚‚ã—ã‚Œãªã„", 
    r"ã ã‚ã†", r"ã§ã—ã‚‡ã†", r"ã‚ˆã†ã ", r"ã¿ãŸã„ã ", r"ã‚‰ã—ã„", r"ã£ã½ã„",
    # é¡˜æœ›ãƒ»å¸Œæœ›è¡¨ç¾
    r"ã—ãŸã„", r"æ¬²ã—ã„", r"å¸Œæœ›", r"é¡˜ã„", r"å¤¢", r"ç›®æ¨™", r"ç†æƒ³", r"æœŸå¾…",
    # ææ¡ˆãƒ»ã‚¢ã‚¤ãƒ‡ã‚¢è¡¨ç¾
    r"ã‚¢ã‚¤ãƒ‡ã‚¢", r"ææ¡ˆ", r"æ¡ˆ", r"æ–¹æ³•", r"ã‚„ã‚Šæ–¹", r"å·¥å¤«", r"æ”¹å–„", r"è§£æ±ºç­–",
    # æ„Ÿæƒ…è¡¨ç¾
    r"å¬‰ã—ã„", r"æ‚²ã—ã„", r"æ¥½ã—ã„", r"é¢ç™½ã„", r"æ€–ã„", r"ä¸å®‰", r"å¿ƒé…", r"å®‰å¿ƒ",
    # æ„è¦‹è¡¨ç¾
    r"æ„è¦‹", r"è€ƒãˆ", r"è¦‹è§£", r"ç«‹å ´", r"è¦–ç‚¹", r"è¦³ç‚¹", r"ä¸»å¼µ", r"è³›æˆ", r"åå¯¾",
    # ä»®å®šè¡¨ç¾
    r"ã‚‚ã—", r"ä»®ã«", r"ãŸã‚‰", r"ã‚Œã°", r"ãªã‚‰", r"ã¨ã™ã‚Œã°", r"ã¨ä»®å®šã™ã‚‹ã¨"
]

def parse_concept_dict_file(file_content):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¦‚å¿µè¾æ›¸ã‚’è§£æã™ã‚‹"""
    concept_dict = {}
    current_category = None
    
    for line in file_content.split('\n'):
        line = line.strip()
        if not line or line.startswith('#'):  # ç©ºè¡Œã¾ãŸã¯ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
            continue
        
        if line.startswith('[') and line.endswith(']'):
            # ã‚«ãƒ†ã‚´ãƒªè¡Œ
            current_category = line[1:-1].strip()
            concept_dict[current_category] = []
        elif current_category is not None:
            # ç”¨èªè¡Œ
            terms = [term.strip() for term in line.split(',')]
            concept_dict[current_category].extend([term for term in terms if term])
    
    return concept_dict

def analyze_text_with_context(text):
    """æ–‡è„ˆã‚’è€ƒæ…®ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€é©åˆ‡ãªãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚’ä»˜ã‘ã‚‹"""
    doc = nlp(text)
    
    # æ–‡ç¯€ã”ã¨ã®åˆ†æçµæœã‚’ä¿å­˜
    segments = []
    
    # æ–‡ã‚’åˆ†å‰²ã—ã¦å‡¦ç†
    for sent in doc.sents:
        sent_text = sent.text
        bracket_applied = False
        
        # å…·ä½“ä¾‹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
        for pattern in example_patterns:
            if re.search(pattern, sent_text):
                sent_text = f"[{sent_text}]"
                bracket_applied = True
                break
        
        if not bracket_applied:
            # æ¦‚å¿µè¾æ›¸ã‚’ä½¿ç”¨ã—ã¦æ¦‚å¿µã‚’æ¤œå‡º
            for category, terms in concept_dict.items():
                for term in terms:
                    if term in sent_text:
                        sent_text = f"ï¼ˆ{sent_text}ï¼‰"
                        bracket_applied = True
                        break
                if bracket_applied:
                    break
        
        if not bracket_applied:
            # ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»æ€ã„ãƒ»æ§‹æƒ³ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
            for pattern in idea_patterns:
                if re.search(pattern, sent_text):
                    sent_text = f"ã€ˆ{sent_text}ã€‰"
                    bracket_applied = True
                    break
        
        segments.append(sent_text)
    
    # æ–‡è„ˆåˆ†æï¼ˆéš£æ¥ã™ã‚‹æ–‡ã®é–¢ä¿‚ã‚’è€ƒæ…®ï¼‰
    # ä¾‹ï¼šã€Œç§ã¯è€ƒãˆã¾ã—ãŸã€ã®å¾Œã«ç¶šãæ–‡ã¯ã€ã‚¢ã‚¤ãƒ‡ã‚¢ã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„
    result = []
    idea_context = False
    
    for i, segment in enumerate(segments):
        if i > 0 and idea_context and not (segment.startswith("[") or segment.startswith("ï¼ˆ") or segment.startswith("ã€ˆ")):
            # å‰ã®æ–‡ãŒã‚¢ã‚¤ãƒ‡ã‚¢æ–‡è„ˆã§ã€ç¾åœ¨ã®æ–‡ã«ãƒ–ãƒ©ã‚±ãƒƒãƒˆãŒãªã„å ´åˆ
            segment = f"ã€ˆ{segment}ã€‰"
        
        # ã‚¢ã‚¤ãƒ‡ã‚¢æ–‡è„ˆã®æ›´æ–°
        idea_context = any(re.search(pattern, segment) for pattern in [r"è€ƒãˆ", r"æ€ã„", r"ã‚¢ã‚¤ãƒ‡ã‚¢", r"ææ¡ˆ"])
        
        result.append(segment)
    
    return "".join(result)

def process_csv(df):
    """CSVãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã€ç™ºè¨€å†…å®¹ã«ãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚’ä»˜ã‘ã‚‹"""
    if 'ç™ºè¨€å†…å®¹' not in df.columns:
        st.error("CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã€Œç™ºè¨€å†…å®¹ã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None
    
    # ç™ºè¨€å†…å®¹ã‚’åˆ†æ
    df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] = df['ç™ºè¨€ï¿½ï¿½å®¹'].apply(analyze_text_with_context)
    
    return df

def get_csv_download_link(df, filename="analyzed_data.csv"):
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’CSVã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ"""
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">åˆ†æçµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
    return href

def get_dict_download_link(dict_data, filename="concept_dictionary.txt"):
    """æ¦‚å¿µè¾æ›¸ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ"""
    content = ""
    for category, terms in dict_data.items():
        content += f"[{category}]\n"
        # 10å€‹ã”ã¨ã«æ”¹è¡Œã—ã¦è¦‹ã‚„ã™ãã™ã‚‹
        for i in range(0, len(terms), 10):
            content += ", ".join(terms[i:i+10]) + "\n"
        content += "\n"
    
    b64 = base64.b64encode(content.encode()).decode()
    href = f'<a href="data:file/txt;base64,{b64}" download="{filename}">æ¦‚å¿µè¾æ›¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
    return href

def get_pattern_download_link(filename="patterns.txt"):
    """ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ"""
    content = "# å…·ä½“ä¾‹ãƒ‘ã‚¿ãƒ¼ãƒ³\n"
    for pattern in example_patterns:
        content += pattern + "\n"
    
    content += "\n# ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»æ€ã„ãƒ»æ§‹æƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³\n"
    for pattern in idea_patterns:
        content += pattern + "\n"
    
    b64 = base64.b64encode(content.encode()).decode()
    href = f'<a href="data:file/txt;base64,{b64}" download="{filename}">ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
    return href

# ç™ºè¨€ã‚’ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥ã«åˆ†è§£ã™ã‚‹é–¢æ•°
def decompose_utterance(text):
    """ç™ºè¨€ã‚’ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥ã«åˆ†è§£ã™ã‚‹"""
    # æœ€ã‚‚å¤–å´ã®ãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚’å„ªå…ˆã—ã¦åˆ†è§£
    result = {
        "ä¾‹ç¤º": [],  # [...]
        "æ¦‚å¿µ": [],  # ï¼ˆ...ï¼‰
        "æ§‹æƒ³": [],  # ã€ˆ...ã€‰
        "ãã®ä»–": []
    }
    
    # æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
    example_pattern = r"\[(.*?)\]"
    concept_pattern = r"ï¼ˆ(.*?)ï¼‰"
    idea_pattern = r"ã€ˆ(.*?)ã€‰"
    
    # æœ€ã‚‚å¤–å´ã®ãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚’æ¤œå‡º
    remaining_text = text
    
    # ä¾‹ç¤ºãƒ–ãƒ©ã‚±ãƒƒãƒˆ [...]
    example_matches = re.findall(example_pattern, remaining_text)
    for match in example_matches:
        result["ä¾‹ç¤º"].append(match)
        remaining_text = remaining_text.replace(f"[{match}]", "", 1)
    
    # æ¦‚å¿µãƒ–ãƒ©ã‚±ãƒƒãƒˆ ï¼ˆ...ï¼‰
    concept_matches = re.findall(concept_pattern, remaining_text)
    for match in concept_matches:
        result["æ¦‚å¿µ"].append(match)
        remaining_text = remaining_text.replace(f"ï¼ˆ{match}ï¼‰", "", 1)
    
    # æ§‹æƒ³ãƒ–ãƒ©ã‚±ãƒƒãƒˆ ã€ˆ...ã€‰
    idea_matches = re.findall(idea_pattern, remaining_text)
    for match in idea_matches:
        result["æ§‹æƒ³"].append(match)
        remaining_text = remaining_text.replace(f"ã€ˆ{match}ã€‰", "", 1)
    
    # æ®‹ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã€Œãã®ä»–ã€ã«è¿½åŠ 
    if remaining_text.strip():
        result["ãã®ä»–"].append(remaining_text.strip())
    
    return result

# ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã™ã‚‹é–¢æ•°
def prepare_matrix_data(df):
    """ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã™ã‚‹"""
    matrix_data = []
    
    for idx, row in df.iterrows():
        utterance_num = row.get('ç™ºè¨€ç•ªå·', idx + 1)
        speaker = row.get('ç™ºè¨€è€…', 'Unknown')
        content = row['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹']
        
        # ç™ºè¨€ã‚’ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥ã«åˆ†è§£
        decomposed = decompose_utterance(content)
        
        # å„ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        for bracket_type, texts in decomposed.items():
            if texts:  # ç©ºã§ãªã„å ´åˆã®ã¿è¿½åŠ 
                matrix_data.append({
                    "ç™ºè¨€ç•ªå·": utterance_num,
                    "ç™ºè¨€è€…": speaker,
                    "ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡": bracket_type,
                    "ãƒ†ã‚­ã‚¹ãƒˆæ•°": len(texts),
                    "ãƒ†ã‚­ã‚¹ãƒˆ": " | ".join(texts[:3]) + ("..." if len(texts) > 3 else ""),
                    "å…¨ãƒ†ã‚­ã‚¹ãƒˆ": " | ".join(texts)
                })
    
    return pd.DataFrame(matrix_data)

# ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ã‚’ä½œæˆã™ã‚‹é–¢æ•°
def create_matrix_visualization(matrix_df, selected_speakers=None):
    """ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ã‚’ä½œæˆã™ã‚‹"""
    if matrix_df.empty:
        # ç©ºã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å ´åˆã¯ç©ºã®ã‚°ãƒ©ãƒ•ã‚’è¿”ã™
        fig = go.Figure()
        fig.update_layout(
            title="ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“",
            xaxis=dict(title="ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡"),
            yaxis=dict(title="ç™ºè¨€ç•ªå·"),
            height=400
        )
        return fig
    
    # ç™ºè¨€è€…ãŒé¸æŠã•ã‚Œã¦ã„ãªã„å ´åˆã¯å…¨ã¦ã®ç™ºè¨€è€…ã‚’é¸æŠ
    if selected_speakers is None or len(selected_speakers) == 0:
        selected_speakers = matrix_df['ç™ºè¨€è€…'].unique().tolist()
    
    # ç™ºè¨€è€…ã”ã¨ã«è‰²ã‚’å‰²ã‚Šå½“ã¦
    speakers = matrix_df['ç™ºè¨€è€…'].unique()
    
    # è‰²ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆï¼ˆå¿…è¦ãªæ•°ã ã‘ï¼‰
    color_list = px.colors.qualitative.Plotly + px.colors.qualitative.D3 + px.colors.qualitative.G10
    # è‰²ãŒè¶³ã‚Šãªã„å ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ ãªè‰²ã‚’ç”Ÿæˆ
    while len(color_list) < len(speakers):
        r = random.randint(0, 255)
        g = random.randint(0, 255)
        b = random.randint(0, 255)
        color_list.append(f"rgb({r},{g},{b})")
    
    # è‰²ãƒãƒƒãƒ—ã‚’ä½œæˆ
    color_map = {speaker: color_list[i % len(color_list)] for i, speaker in enumerate(speakers)}
    
    # é¸æŠã•ã‚ŒãŸç™ºè¨€è€…ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    filtered_df = matrix_df.copy()
    
    # é¸æŠã•ã‚ŒãŸç™ºè¨€è€…ã¨ãã‚Œä»¥å¤–ã§é€æ˜åº¦ã‚’å¤‰ãˆã‚‹
    filtered_df['é¸æŠçŠ¶æ…‹'] = filtered_df['ç™ºè¨€è€…'].apply(
        lambda x: 'é¸æŠæ¸ˆã¿' if x in selected_speakers else 'éé¸æŠ'
    )
    
    # ãƒãƒ¼ã‚«ãƒ¼ã‚µã‚¤ã‚ºã®èª¿æ•´
    max_size = filtered_df['ãƒ†ã‚­ã‚¹ãƒˆæ•°'].max() if not filtered_df.empty else 1
    filtered_df['ãƒãƒ¼ã‚«ãƒ¼ã‚µã‚¤ã‚º'] = filtered_df['ãƒ†ã‚­ã‚¹ãƒˆæ•°'].apply(
        lambda x: max(10, min(30, 10 + (x / max_size) * 20))
    )
    
    # ãƒ›ãƒãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®ä½œæˆ
    filtered_df['ãƒ›ãƒãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ'] = filtered_df.apply(
        lambda row: f"ç™ºè¨€ç•ªå·: {row['ç™ºè¨€ç•ªå·']}<br>ç™ºè¨€è€…: {row['ç™ºè¨€è€…']}<br>ãƒ–ãƒ©ã‚±ãƒƒãƒˆ: {row['ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡']}<br>å†…å®¹: {row['å…¨ãƒ†ã‚­ã‚¹ãƒˆ']}",
        axis=1
    )
    
    # ç™ºè¨€è€…ã”ã¨ã®ãƒãƒ¼ã‚«ãƒ¼ã‚·ãƒ³ãƒœãƒ«ã‚’è¨­å®š
    marker_symbols = {speaker: idx for idx, speaker in enumerate(speakers)}
    filtered_df['ãƒãƒ¼ã‚«ãƒ¼ã‚·ãƒ³ãƒœãƒ«'] = filtered_df['ç™ºè¨€è€…'].map(marker_symbols)
    
    # é¸æŠçŠ¶æ…‹ã«å¿œã˜ãŸãƒãƒ¼ã‚«ãƒ¼ã®è¨­å®š
    filtered_df['ãƒãƒ¼ã‚«ãƒ¼è¡¨ç¤º'] = filtered_df['é¸æŠçŠ¶æ…‹'].apply(
        lambda x: 'ğŸ”¸' if x == 'é¸æŠæ¸ˆã¿' else 'âšª'
    )
    
    # ãƒ—ãƒ­ãƒƒãƒˆã®ä½œæˆ
    fig = go.Figure()
    
    # éé¸æŠã®ç™ºè¨€è€…ã‚’å…ˆã«è¿½åŠ ï¼ˆé€æ˜åº¦ã‚’ä¸‹ã’ã‚‹ï¼‰
    non_selected = filtered_df[filtered_df['é¸æŠçŠ¶æ…‹'] == 'éé¸æŠ']
    for speaker in non_selected['ç™ºè¨€è€…'].unique():
        speaker_df = non_selected[non_selected['ç™ºè¨€è€…'] == speaker]
        
        # è‰²ãƒãƒƒãƒ—ã«ãªã„ç™ºè¨€è€…ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè‰²ã‚’ä½¿ç”¨
        speaker_color = color_map.get(speaker, "gray")
        
        fig.add_trace(go.Scatter(
            x=speaker_df['ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡'],
            y=speaker_df['ç™ºè¨€ç•ªå·'],
            mode='markers+text',
            marker=dict(
                size=speaker_df['ãƒãƒ¼ã‚«ãƒ¼ã‚µã‚¤ã‚º'],
                color=speaker_color,
                opacity=0.3,
                line=dict(width=0)
            ),
            text=speaker_df['ãƒãƒ¼ã‚«ãƒ¼è¡¨ç¤º'],
            textposition="middle center",
            name=speaker,
            hovertext=speaker_df['ãƒ›ãƒãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ'],
            hoverinfo='text',
            showlegend=True
        ))
    
    # é¸æŠã•ã‚ŒãŸç™ºè¨€è€…ã‚’å¾Œã«è¿½åŠ ï¼ˆé€šå¸¸ã®é€æ˜åº¦ï¼‰
    selected = filtered_df[filtered_df['é¸æŠçŠ¶æ…‹'] == 'é¸æŠæ¸ˆã¿']
    for speaker in selected['ç™ºè¨€è€…'].unique():
        speaker_df = selected[selected['ç™ºè¨€è€…'] == speaker]
        
        # è‰²ãƒãƒƒãƒ—ã«ãªã„ç™ºè¨€è€…ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè‰²ã‚’ä½¿ç”¨
        speaker_color = color_map.get(speaker, "blue")
        
        fig.add_trace(go.Scatter(
            x=speaker_df['ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡'],
            y=speaker_df['ç™ºè¨€ç•ªå·'],
            mode='markers+text',
            marker=dict(
                size=speaker_df['ãƒãƒ¼ã‚«ãƒ¼ã‚µã‚¤ã‚º'],
                color=speaker_color,
                opacity=1.0,
                line=dict(width=1, color='black')
            ),
            text=speaker_df['ãƒãƒ¼ã‚«ãƒ¼è¡¨ç¤º'],
            textposition="middle center",
            name=speaker,
            hovertext=speaker_df['ãƒ›ãƒãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ'],
            hoverinfo='text',
            showlegend=True
        ))
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®è¨­å®š
    fig.update_layout(
        title="ç™ºè¨€å†…å®¹ã®ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–",
        xaxis=dict(
            title="ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡",
            categoryorder='array',
            categoryarray=['ä¾‹ç¤º', 'æ¦‚å¿µ', 'æ§‹æƒ³', 'ãã®ä»–']
        ),
        yaxis=dict(
            title="ç™ºè¨€ç•ªå·",
            autorange="reversed"  # ç™ºè¨€ç•ªå·ã‚’ä¸Šã‹ã‚‰ä¸‹ã«è¡¨ç¤º
        ),
        height=max(500, min(1000, len(filtered_df['ç™ºè¨€ç•ªå·'].unique()) * 30)) if not filtered_df.empty else 400,
        margin=dict(l=50, r=50, t=80, b=50),
        hovermode='closest',
        legend=dict(
            title="ç™ºè¨€è€…",
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    
    return fig

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š
st.sidebar.header("è¨­å®š")

# æ¦‚å¿µè¾æ›¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
st.sidebar.subheader("æ¦‚å¿µè¾æ›¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
dict_file = st.sidebar.file_uploader("æ¦‚å¿µè¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["txt"])

if dict_file is not None:
    try:
        dict_content = dict_file.getvalue().decode("utf-8")
        uploaded_dict = parse_concept_dict_file(dict_content)
        if uploaded_dict:
            concept_dict = uploaded_dict
            st.sidebar.success("æ¦‚å¿µè¾æ›¸ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
        else:
            st.sidebar.warning("æœ‰åŠ¹ãªæ¦‚å¿µè¾æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¾æ›¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    except Exception as e:
        st.sidebar.error(f"è¾æ›¸ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.sidebar.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¾æ›¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

# æ¦‚å¿µè¾æ›¸ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ã‚’è¡¨ç¤º
st.sidebar.subheader("æ¦‚å¿µè¾æ›¸ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹")
dict_format_example = """
# æ¦‚å¿µè¾æ›¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹
[æ•™ç§‘ãƒ»å˜å…ƒãƒ»æˆæ¥­æ¦‚å¿µ]
æ•°å­¦, ç®—æ•°, å›½èª, ç†ç§‘, ç¤¾ä¼š
æ–¹ç¨‹å¼, é–¢æ•°, å›³å½¢, ç¢ºç‡, çµ±è¨ˆ

[ç¤¾ä¼šçš„æ¦‚å¿µ]
æ°‘ä¸»ä¸»ç¾©, äººæ¨©, ç’°å¢ƒ, æŒç¶šå¯èƒ½æ€§
å¤šæ§˜æ€§, å…¬æ­£, å¹³ç­‰, è‡ªç”±, è²¬ä»»

# ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã¯#ã§å§‹ã‚ã¾ã™
"""
st.sidebar.code(dict_format_example, language="text")

# ç¾åœ¨ã®æ¦‚å¿µè¾æ›¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
if st.sidebar.button("ç¾åœ¨ã®æ¦‚å¿µè¾æ›¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
    st.sidebar.markdown(get_dict_download_link(concept_dict), unsafe_allow_html=True)

# ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
st.sidebar.subheader("ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
pattern_file = st.sidebar.file_uploader("ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["txt"])

if pattern_file is not None:
    try:
        pattern_content = pattern_file.getvalue().decode("utf-8")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’è§£æ
        new_example_patterns = []
        new_idea_patterns = []
        current_section = None
        
        for line in pattern_content.split('\n'):
            line = line.strip()
            if not line or line.startswith('#'):
                if "å…·ä½“ä¾‹" in line:
                    current_section = "example"
                elif "ã‚¢ã‚¤ãƒ‡ã‚¢" in line or "æ€ã„" in line or "æ§‹æƒ³" in line:
                    current_section = "idea"
                continue
            
            if current_section == "example":
                new_example_patterns.append(line)
            elif current_section == "idea":
                new_idea_patterns.append(line)
        
        if new_example_patterns:
            example_patterns = new_example_patterns
        if new_idea_patterns:
            idea_patterns = new_idea_patterns
            
        st.sidebar.success("ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    except Exception as e:
        st.sidebar.error(f"ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

# ç¾åœ¨ã®ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
if st.sidebar.button("ç¾åœ¨ã®ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
    st.sidebar.markdown(get_pattern_download_link(), unsafe_allow_html=True)

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
st.sidebar.subheader("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å½¢å¼")
sample_data = pd.DataFrame({
    'ç™ºè¨€ç•ªå·': [1, 2, 3, 4, 5],
    'ç™ºè¨€è€…': ['æ•™å¸«', 'ç”Ÿå¾’A', 'ç”Ÿå¾’B', 'ç”Ÿå¾’C', 'æ•™å¸«'],
    'ç™ºè¨€å†…å®¹': [
        'ä»Šæ—¥ã¯ä¸‰è§’å½¢ã®é¢ç©ã«ã¤ã„ã¦å­¦ã³ã¾ã—ã‚‡ã†ã€‚',
        'ä¾‹ãˆã°ã€ã“ã®å›³å½¢ã®é¢ç©ã¯ã©ã†ã‚„ã£ã¦æ±‚ã‚ã¾ã™ã‹ï¼Ÿ',
        'åº•è¾ºÃ—é«˜ã•Ã·2ã ã¨æ€ã„ã¾ã™ã€‚',
        'æ˜¨æ—¥ã€ãŠçˆ¶ã•ã‚“ã¨ä¸€ç·’ã«å…¬åœ’ã§ä¸‰è§’å½¢ã®çœ‹æ¿ã‚’è¦‹ã¾ã—ãŸã€‚',
        'ã¿ãªã•ã‚“ã®è€ƒãˆã‚’èã‹ã›ã¦ãã ã•ã„ã€‚'
    ]
})
st.sidebar.dataframe(sample_data)

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
use_sample = st.checkbox("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨")

# åˆ†æè¨­å®š
st.sidebar.subheader("åˆ†æè¨­å®š")
show_patterns = st.sidebar.checkbox("ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºè¨­å®šã‚’è¡¨ç¤º")

if show_patterns:
    st.sidebar.subheader("å…·ä½“ä¾‹ãƒ‘ã‚¿ãƒ¼ãƒ³")
    example_patterns_text = st.sidebar.text_area("å…·ä½“ä¾‹ã‚’ç¤ºã™è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ1è¡Œã«1ã¤ï¼‰", 
                                               "\n".join(p for p in example_patterns))
    
    st.sidebar.subheader("ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ‘ã‚¿ãƒ¼ãƒ³")
    idea_patterns_text = st.sidebar.text_area("ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»æ€ã„ãƒ»æ§‹æƒ³ã‚’ç¤ºã™è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ1è¡Œã«1ã¤ï¼‰", 
                                            "\n".join(p for p in idea_patterns))
    
    if st.sidebar.button("ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’æ›´æ–°"):
        example_patterns = [p.strip() for p in example_patterns_text.split("\n") if p.strip()]
        idea_patterns = [p.strip() for p in idea_patterns_text.split("\n") if p.strip()]
        st.sidebar.success("ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")

# åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³
st.sidebar.subheader("åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³")
enable_context_analysis = st.sidebar.checkbox("æ–‡è„ˆåˆ†æã‚’æœ‰åŠ¹ã«ã™ã‚‹", value=True)
bracket_overlap_strategy = st.sidebar.radio(
    "ãƒ–ãƒ©ã‚±ãƒƒãƒˆé‡è¤‡æ™‚ã®æˆ¦ç•¥",
    ["å„ªå…ˆé †ä½ï¼ˆå…·ä½“ä¾‹ > æ¦‚å¿µ > ã‚¢ã‚¤ãƒ‡ã‚¢ï¼‰", "æœ€é•·ä¸€è‡´", "é‡è¤‡ã‚’è¨±å¯ï¼ˆå…¥ã‚Œå­ï¼‰"]
)

# åˆ†æçµæœã®çµ±è¨ˆ
def show_analysis_stats(df):
    if 'analyzed' not in st.session_state:
        st.session_state.analyzed = True
        
        total_utterances = len(df)
        example_count = sum(1 for text in df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if '[' in text)
        concept_count = sum(1 for text in df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if 'ï¼ˆ' in text)
        idea_count = sum(1 for text in df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if 'ã€ˆ' in text)
        
        st.subheader("åˆ†æçµ±è¨ˆ")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ç·ç™ºè¨€æ•°", total_utterances)
        with col2:
            st.metric("å…·ä½“ä¾‹ [ã€€]", example_count, f"{example_count/total_utterances:.1%}" if total_utterances > 0 else "0%")
        with col3:
            st.metric("æ¦‚å¿µ ï¼ˆã€€ï¼‰", concept_count, f"{concept_count/total_utterances:.1%}" if total_utterances > 0 else "0%")
        with col4:
            st.metric("ã‚¢ã‚¤ãƒ‡ã‚¢ ã€ˆã€€ã€‰", idea_count, f"{idea_count/total_utterances:.1%}" if total_utterances > 0 else "0%")
        
        # ç™ºè¨€è€…åˆ¥ã®çµ±è¨ˆ
        if 'ç™ºè¨€è€…' in df.columns:
            st.subheader("ç™ºè¨€è€…åˆ¥ã®åˆ†æ")
            speaker_stats = {}
            
            for speaker in df['ç™ºè¨€è€…'].unique():
                speaker_df = df[df['ç™ºè¨€è€…'] == speaker]
                speaker_total = len(speaker_df)
                speaker_example = sum(1 for text in speaker_df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if '[' in text)
                speaker_concept = sum(1 for text in speaker_df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if 'ï¼ˆ' in text)
                speaker_idea = sum(1 for text in speaker_df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if 'ã€ˆ' in text)
                
                speaker_stats[speaker] = {
                    "ç·ç™ºè¨€æ•°": speaker_total,
                    "å…·ä½“ä¾‹": speaker_example,
                    "æ¦‚å¿µ": speaker_concept,
                    "ã‚¢ã‚¤ãƒ‡ã‚¢": speaker_idea
                }
            
            speaker_df = pd.DataFrame(speaker_stats).T
            st.dataframe(speaker_df)
            
            # ç™ºè¨€è€…åˆ¥ã®ã‚°ãƒ©ãƒ•
            st.subheader("ç™ºè¨€è€…åˆ¥ã®ãƒ–ãƒ©ã‚±ãƒƒãƒˆåˆ†å¸ƒ")
            speaker_chart_data = pd.DataFrame({
                "ç™ºè¨€è€…": list(speaker_stats.keys()) * 3,
                "ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡": ["å…·ä½“ä¾‹"] * len(speaker_stats) + ["æ¦‚å¿µ"] * len(speaker_stats) + ["ã‚¢ã‚¤ãƒ‡ã‚¢"] * len(speaker_stats),
                "ç™ºè¨€æ•°": [stats["å…·ä½“ä¾‹"] for stats in speaker_stats.values()] + 
                         [stats["æ¦‚å¿µ"] for stats in speaker_stats.values()] + 
                         [stats["ã‚¢ã‚¤ãƒ‡ã‚¢"] for stats in speaker_stats.values()]
            })
            
            st.bar_chart(speaker_chart_data, x="ç™ºè¨€è€…", y="ç™ºè¨€æ•°", color="ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡")

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
analyzed_df = None

if uploaded_file is not None:
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    try:
        df = pd.read_csv(uploaded_file)
        st.subheader("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿")
        st.dataframe(df)
        
        analyzed_df = process_csv(df)
        if analyzed_df is not None:
            st.subheader("åˆ†æçµæœ")
            st.dataframe(analyzed_df)
            st.markdown(get_csv_download_link(analyzed_df), unsafe_allow_html=True)
            
            # åˆ†æçµ±è¨ˆã‚’è¡¨ç¤º
            show_analysis_stats(analyzed_df)
            
            # è©³ç´°ãªåˆ†æçµæœã®è¡¨ç¤º
            st.subheader("ç™ºè¨€å†…å®¹ã®è©³ç´°åˆ†æ")
            for idx, row in analyzed_df.iterrows():
                with st.expander(f"ç™ºè¨€ {row['ç™ºè¨€ç•ªå·']} - {row['ç™ºè¨€è€…']}"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("**å…ƒã®ç™ºè¨€å†…å®¹:**")
                        st.write(row['ç™ºè¨€å†…å®¹'])
                    with col2:
                        st.markdown("**åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹:**")
                        st.write(row['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'])
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

elif use_sample:
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
    st.subheader("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿")
    st.dataframe(sample_data)
    
    analyzed_df = process_csv(sample_data)
    if analyzed_df is not None:
        st.subheader("åˆ†æçµæœ")
        st.dataframe(analyzed_df)
        st.markdown(get_csv_download_link(analyzed_df, "sample_analyzed_data.csv"), unsafe_allow_html=True)
        
        # åˆ†æçµ±è¨ˆã‚’è¡¨ç¤º
        show_analysis_stats(analyzed_df)
        
        # è©³ç´°ãªåˆ†æçµæœã®è¡¨ç¤º
        st.subheader("ç™ºè¨€å†…å®¹ã®è©³ç´°åˆ†æ")
        for idx, row in analyzed_df.iterrows():
            with st.expander(f"ç™ºè¨€ {row['ç™ºè¨€ç•ªå·']} - {row['ç™ºè¨€è€…']}"):
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**å…ƒã®ç™ºè¨€å†…å®¹:**")
                    st.write(row['ç™ºè¨€å†…å®¹'])
                with col2:
                    st.markdown("**åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹:**")
                    st.write(row['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'])
else:
    st.info("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")

# ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ã‚»ã‚¯ã‚·ãƒ§ãƒ³
if analyzed_df is not None:
    st.header("ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–")
    
    try:
        # ãƒãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        matrix_df = prepare_matrix_data(analyzed_df)
        
        if not matrix_df.empty:
            # ç™ºè¨€è€…é¸æŠ
            speakers = analyzed_df['ç™ºè¨€è€…'].unique().tolist()
            selected_speakers = st.multiselect(
                "ç™ºè¨€è€…ã‚’é¸æŠï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                options=speakers,
                default=speakers
            )
            
            # ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ã®è¡¨ç¤º
            matrix_fig = create_matrix_visualization(matrix_df, selected_speakers)
            st.plotly_chart(matrix_fig, use_container_width=True)
            
            # ãƒãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°è¡¨ç¤º
            with st.expander("ãƒãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°"):
                st.dataframe(matrix_df)
        else:
            st.warning("ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    except Exception as e:
        st.error(f"ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.info("ãƒ‡ãƒãƒƒã‚°æƒ…å ±: ãƒãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã¾ãŸã¯è¡¨ç¤ºã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")

# ãƒ˜ãƒ«ãƒ—ã‚»ã‚¯ã‚·ãƒ§ãƒ³
with st.expander("ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰"):
    st.markdown("""
    ## æˆæ¥­è¨˜éŒ²åˆ†æãƒ„ãƒ¼ãƒ«ã®ä½¿ã„æ–¹
    
    ### åŸºæœ¬çš„ãªä½¿ã„æ–¹
    1. CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™
    2. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒè‡ªå‹•çš„ã«ç™ºè¨€å†…å®¹ã‚’åˆ†æã—ã€é©åˆ‡ãªãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚’ä»˜ã‘ã¾ã™
    3. åˆ†æçµæœã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™
    
    ### ãƒ–ãƒ©ã‚±ãƒƒãƒˆã®ç¨®é¡
    - **[ã€€]** - å…·ä½“çš„ãªäº‹ä¾‹ï¼ˆä¾‹ï¼šã€Œä¾‹ãˆã°ã€œã€ã€Œæ˜¨æ—¥ã€œã€ã€Œã€œã•ã‚“ã¯ã€ãªã©ï¼‰
    - **ï¼ˆã€€ï¼‰** - æ•™ç§‘ãƒ»å­¦ç¿’å†…å®¹ãƒ»ç¤¾ä¼šçš„æ¦‚å¿µï¼ˆæ¦‚å¿µè¾æ›¸ã«åŸºã¥ãï¼‰
    - **ã€ˆã€€ã€‰** - å…ç«¥ç”Ÿå¾’ã®ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»æ€ã„ãƒ»æ§‹æƒ³ï¼ˆã€Œæ€ã„ã¾ã™ã€ã€Œè€ƒãˆã¾ã™ã€ãªã©ï¼‰
    
    ### ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
    - **æ¦‚å¿µè¾æ›¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§æ¦‚å¿µè¾æ›¸ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™
    - **ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®š**: å…·ä½“ä¾‹ã‚„ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™
    - **åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³**: æ–‡è„ˆåˆ†æã‚„ãƒ–ãƒ©ã‚±ãƒƒãƒˆé‡è¤‡æ™‚ã®æˆ¦ç•¥ã‚’è¨­å®šã§ãã¾ã™
    
    ### ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ã®ä½¿ã„æ–¹
    1. åˆ†æçµæœãŒè¡¨ç¤ºã•ã‚ŒãŸå¾Œã€ã€Œãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
    2. ç™ºè¨€è€…ã‚’é¸æŠã™ã‚‹ã¨ã€é¸æŠã•ã‚ŒãŸç™ºè¨€è€…ã®ç™ºè¨€ãŒãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºã•ã‚Œã¾ã™
    3. ãƒãƒˆãƒªã‚¯ã‚¹ã§ã¯ã€ç¸¦è»¸ã«ç™ºè¨€ç•ªå·ã€æ¨ªè»¸ã«ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
    4. ç‚¹ã®å¤§ãã•ã¯ã€ãã®ç™ºè¨€ã«ãŠã‘ã‚‹ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡ã®å‡ºç¾å›æ•°ã‚’è¡¨ã—ã¾ã™
    5. ç‚¹ã«ã‚«ãƒ¼ã‚½ãƒ«ã‚’åˆã‚ã›ã‚‹ã¨ã€è©³ç´°æƒ…å ±ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
    
    ### æ¦‚å¿µè¾æ›¸ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    \`\`\`
    [ã‚«ãƒ†ã‚´ãƒªå]
    ç”¨èª1, ç”¨èª2, ç”¨èª3
    ç”¨èª4, ç”¨èª5, ç”¨èª6
    
    [åˆ¥ã®ã‚«ãƒ†ã‚´ãƒª]
    ç”¨èªA, ç”¨èªB, ç”¨èªC
    \`\`\`
    
    ### ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    \`\`\`
    # å…·ä½“ä¾‹ãƒ‘ã‚¿ãƒ¼ãƒ³
    ãƒ‘ã‚¿ãƒ¼ãƒ³1
    ãƒ‘ã‚¿ãƒ¼ãƒ³2
    
    # ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»æ€ã„ãƒ»æ§‹æƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³
    ãƒ‘ã‚¿ãƒ¼ãƒ³3
    ãƒ‘ã‚¿ãƒ¼ãƒ³4
    \`\`\`
    """)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("Â© 2025 æˆæ¥­è¨˜éŒ²åˆ†æãƒ„ãƒ¼ãƒ« | ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–æ©Ÿèƒ½ä»˜ã")
