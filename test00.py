import streamlit as st
import pandas as pd
import spacy
import re
import json
import base64
from io import StringIO
import os
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import numpy as np

# ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
st.set_page_config(page_title="æˆæ¥­è¨˜éŒ²åˆ†æãƒ„ãƒ¼ãƒ«", layout="wide")
st.title("æˆæ¥­è¨˜éŒ²åˆ†æãƒ„ãƒ¼ãƒ«")
st.markdown("ç™ºè¨€å†…å®¹ã‚’åˆ†æã—ã€ç‰¹å®šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚’ä»˜ã‘ã¾ã™")

# spaCyãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
@st.cache_resource
def load_nlp_model():
    try:
        return spacy.load("ja_core_news_sm")
    except OSError:
        st.info("æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...")
        spacy.cli.download("ja_core_news_sm")
        return spacy.load("ja_core_news_sm")

nlp = load_nlp_model()

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ¦‚å¿µè¾æ›¸
default_concept_dict = {
    # æ•™ç§‘ãƒ»å˜å…ƒãƒ»æˆæ¥­æ¦‚å¿µ
    "æ•™ç§‘ãƒ»å˜å…ƒãƒ»æˆæ¥­æ¦‚å¿µ": [
        "æ•°", "è¶³ã—ç®—", "å¼•ãç®—", "æ›ã‘ç®—", "å‰²ã‚Šç®—", "æ–¹ç¨‹å¼", "é–¢æ•°", "å›³å½¢", "ç¢ºç‡",
        "ç‰©èª", "æ–‡ç« ", "èª­è§£", "è¡¨ç¾", "æ–‡æ³•", "æ¼¢å­—", "æ–‡å­¦", "è©©",
        "å®Ÿé¨“", "è¦³å¯Ÿ", "ç”Ÿç‰©", "åŒ–å­¦", "ç‰©ç†", "åœ°å­¦", "å…ƒç´ ", "åå¿œ", "ã‚¨ãƒãƒ«ã‚®ãƒ¼",
        "æ­´å²", "åœ°ç†", "æ”¿æ²»", "çµŒæ¸ˆ", "æ–‡åŒ–", "ç¤¾ä¼š", "å›½éš›", "ç’°å¢ƒ",
        "å˜å…ƒ", "æˆæ¥­", "å­¦ç¿’", "æ•™æ", "ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ "
    ],
    
    # ç¤¾ä¼šçš„æ¦‚å¿µ
    "ç¤¾ä¼šçš„æ¦‚å¿µ": [
        "é“å¾³", "æ­£ç¾©", "æ¨©åˆ©", "è²¬ä»»", "å¹³ç­‰", "è‡ªç”±", "å°Šé‡", "å”åŠ›", "å…±ç”Ÿ",
        "å¤šæ§˜æ€§", "æŒç¶šå¯èƒ½æ€§", "æ°‘ä¸»ä¸»ç¾©", "å¸‚æ°‘æ€§", "ã‚°ãƒ­ãƒ¼ãƒãƒ«", "åœ°åŸŸ", "ä¼çµ±",
        "å¯¾è©±", "è­°è«–", "ç™ºè¡¨", "å”åŠ›", "ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯", "æ„è¦‹", "åˆæ„å½¢æˆ"
    ],
    
    # æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹
    "æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹": [
        "è€ƒãˆ", "ã‚¢ã‚¤ãƒ‡ã‚¢", "ä»®èª¬", "äºˆæƒ³", "æ¨æ¸¬", "åˆ†æ", "è©•ä¾¡", "åˆ¤æ–­",
        "å‰µé€ ", "æ‰¹åˆ¤çš„æ€è€ƒ", "å•é¡Œè§£æ±º", "ãƒ¡ã‚¿èªçŸ¥", "æŒ¯ã‚Šè¿”ã‚Š", "è¨ˆç”»"
    ]
}

# æ¦‚å¿µè¾æ›¸ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦åˆæœŸåŒ–
concept_dict = default_concept_dict.copy()

# å…·ä½“ä¾‹ã‚’ç¤ºã™è¡¨ç¾ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ‹¡å¼µç‰ˆï¼‰
example_patterns = [
    # æ˜ç¤ºçš„ãªä¾‹ç¤ºè¡¨ç¾
    r"ä¾‹ãˆã°[ã€,]", r"ãŸã¨ãˆã°[ã€,]", r"å…·ä½“çš„ã«ã¯", r"å…·ä½“ä¾‹", r"äº‹ä¾‹", r"å®Ÿä¾‹", 
    # æ™‚é–“ã‚„å ´æ‰€ã®å…·ä½“çš„è¡¨ç¾
    r"\d+æœˆ\d+æ—¥", r"æ˜¨æ—¥", r"å…ˆæ—¥", r"å…ˆé€±", r"ä»Šæ—¥", r"æ˜æ—¥", r"åˆå‰", r"åˆå¾Œ", 
    r"ã€œæ™‚", r"ã€œåˆ†", r"ã€œå¹´", r"ã€œæœˆ", r"ã€œæ—¥",
    # äººç‰©ã‚„æ‰€æœ‰ç‰©ã®è¡¨ç¾
    r"ã€œã•ã‚“ã¯", r"ã€œãã‚“ã¯", r"ã€œã¡ã‚ƒã‚“ã¯", r"ç§ã¯", r"åƒ•ã¯", r"ã‚ãŸã—ã¯", r"ã¼ãã¯", 
    r"ç§ã®", r"åƒ•ã®", r"ã‚ãŸã—ã®", r"ã¼ãã®", r"æŒã£ã¦ã„ã‚‹", r"è²·ã£ãŸ", r"ã‚‚ã‚‰ã£ãŸ",
    # å ´æ‰€ã‚„åº—èˆ—ã®è¡¨ç¾
    r"ã€œåº—", r"ã€œå±‹", r"ã€œé¤¨", r"ã€œåœ’", r"ã€œå…¬åœ’", r"ã€œå­¦æ ¡", r"ã€œé§…", r"ã€œå¸‚", r"ã€œçœŒ", 
    r"ã€œç”º", r"ã€œæ‘", r"ã€œåœ°åŒº", r"ã€œã‚»ãƒ³ã‚¿ãƒ¼",
    # æ•°é‡è¡¨ç¾
    r"\d+å€‹", r"\d+å††", r"\d+äºº", r"\d+åŒ¹", r"\d+å°", r"\d+æœ¬", r"\d+å†Š", r"\d+å›",
    # çµŒé¨“è¡¨ç¾
    r"è¡Œã£ãŸ", r"è¦‹ãŸ", r"èã„ãŸ", r"æ„Ÿã˜ãŸ", r"ä½“é¨“", r"çµŒé¨“", r"ã‚„ã£ã¦ã¿ãŸ", r"è©¦ã—ãŸ"
]

# ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»æ€ã„ãƒ»æ§‹æƒ³ã‚’ç¤ºã™è¡¨ç¾ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ‹¡å¼µç‰ˆï¼‰
idea_patterns = [
    # æ€è€ƒè¡¨ç¾
    r"æ€ã„ã¾ã™", r"è€ƒãˆã¾ã™", r"æ„Ÿã˜ã¾ã™", r"ã ã¨æ€ã†", r"ã§ã¯ãªã„ã‹", r"ã‹ã‚‚ã—ã‚Œãªã„", 
    r"ã ã‚ã†", r"ã§ã—ã‚‡ã†", r"ã‚ˆã†ã ", r"ã¿ãŸã„ã ", r"ã‚‰ã—ã„", r"ã£ã½ã„",
    # é¡˜æœ›ãƒ»å¸Œæœ›è¡¨ç¾
    r"ã—ãŸã„", r"æ¬²ã—ã„", r"å¸Œæœ›", r"é¡˜ã„", r"å¤¢", r"ç›®æ¨™", r"ç†æƒ³", r"æœŸå¾…",
    # ææ¡ˆãƒ»ã‚¢ã‚¤ãƒ‡ã‚¢è¡¨ç¾
    r"ã‚¢ã‚¤ãƒ‡ã‚¢", r"ææ¡ˆ", r"æ¡ˆ", r"æ–¹æ³•", r"ã‚„ã‚Šæ–¹", r"å·¥å¤«", r"æ”¹å–„", r"è§£æ±ºç­–",
    # æ„Ÿæƒ…è¡¨ç¾
    r"å¬‰ã—ã„", r"æ‚²ã—ã„", r"æ¥½ã—ã„", r"é¢ç™½ã„", r"æ€–ã„", r"ä¸å®‰", r"å¿ƒé…", r"å®‰å¿ƒ",
    # æ„è¦‹è¡¨ç¾
    r"æ„è¦‹", r"è€ƒãˆ", r"è¦‹è§£", r"ç«‹å ´", r"è¦–ç‚¹", r"è¦³ç‚¹", r"ä¸»å¼µ", r"è³›æˆ", r"åå¯¾",
    # ä»®å®šè¡¨ç¾
    r"ã‚‚ã—", r"ä»®ã«", r"ãŸã‚‰", r"ã‚Œã°", r"ãªã‚‰", r"ã¨ã™ã‚Œã°", r"ã¨ä»®å®šã™ã‚‹ã¨"
]

def parse_concept_dict_file(file_content):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¦‚å¿µè¾æ›¸ã‚’è§£æã™ã‚‹"""
    concept_dict = {}
    current_category = None
    
    for line in file_content.split('\n'):
        line = line.strip()
        if not line or line.startswith('#'):  # ç©ºè¡Œã¾ãŸã¯ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
            continue
        
        if line.startswith('[') and line.endswith(']'):
            # ã‚«ãƒ†ã‚´ãƒªè¡Œ
            current_category = line[1:-1].strip()
            concept_dict[current_category] = []
        elif current_category is not None:
            # ç”¨èªè¡Œ
            terms = [term.strip() for term in line.split(',')]
            concept_dict[current_category].extend([term for term in terms if term])
    
    return concept_dict

def get_bracket_type(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æœ€ã‚‚å¤–å´ã®ãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚¿ã‚¤ãƒ—ã‚’å–å¾—"""
    if text.startswith('[') and text.endswith(']'):
        return "ä¾‹ç¤º"
    elif text.startswith('ï¼ˆ') and text.endswith('ï¼‰'):
        return "æ¦‚å¿µ"
    elif text.startswith('ã€ˆ') and text.endswith('ã€‰'):
        return "æ§‹æƒ³"
    else:
        return "ãã®ä»–"

def decompose_utterance_by_brackets(text):
    """ç™ºè¨€ã‚’ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥ã«åˆ†è§£"""
    # ãƒ–ãƒ©ã‚±ãƒƒãƒˆã§å›²ã¾ã‚ŒãŸéƒ¨åˆ†ã‚’æŠ½å‡º
    bracket_segments = {
        "ä¾‹ç¤º": [],
        "æ¦‚å¿µ": [],
        "æ§‹æƒ³": [],
        "ãã®ä»–": []
    }
    
    # å„ç¨®ãƒ–ãƒ©ã‚±ãƒƒãƒˆã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
    example_matches = re.findall(r'\[([^\]]+)\]', text)
    concept_matches = re.findall(r'ï¼ˆ([^ï¼‰]+)ï¼‰', text)
    idea_matches = re.findall(r'ã€ˆ([^ã€‰]+)ã€‰', text)
    
    # ãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚’é™¤å»ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
    clean_text = text
    clean_text = re.sub(r'\[[^\]]+\]', '', clean_text)
    clean_text = re.sub(r'ï¼ˆ[^ï¼‰]+ï¼‰', '', clean_text)
    clean_text = re.sub(r'ã€ˆ[^ã€‰]+ã€‰', '', clean_text)
    clean_text = clean_text.strip()
    
    bracket_segments["ä¾‹ç¤º"] = example_matches
    bracket_segments["æ¦‚å¿µ"] = concept_matches
    bracket_segments["æ§‹æƒ³"] = idea_matches
    if clean_text:
        bracket_segments["ãã®ä»–"] = [clean_text]
    
    return bracket_segments

def analyze_text_with_context(text):
    """æ–‡è„ˆã‚’è€ƒæ…®ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€é©åˆ‡ãªãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚’ä»˜ã‘ã‚‹"""
    doc = nlp(text)
    
    # æ–‡ç¯€ã”ã¨ã®åˆ†æçµæœã‚’ä¿å­˜
    segments = []
    
    # æ–‡ã‚’åˆ†å‰²ã—ã¦å‡¦ç†
    for sent in doc.sents:
        sent_text = sent.text
        bracket_applied = False
        
        # å…·ä½“ä¾‹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
        for pattern in example_patterns:
            if re.search(pattern, sent_text):
                sent_text = f"[{sent_text}]"
                bracket_applied = True
                break
        
        if not bracket_applied:
            # æ¦‚å¿µè¾æ›¸ã‚’ä½¿ç”¨ã—ã¦æ¦‚å¿µã‚’æ¤œå‡º
            for category, terms in concept_dict.items():
                for term in terms:
                    if term in sent_text:
                        sent_text = f"ï¼ˆ{sent_text}ï¼‰"
                        bracket_applied = True
                        break
                if bracket_applied:
                    break
        
        if not bracket_applied:
            # ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»æ€ã„ãƒ»æ§‹æƒ³ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
            for pattern in idea_patterns:
                if re.search(pattern, sent_text):
                    sent_text = f"ã€ˆ{sent_text}ã€‰"
                    bracket_applied = True
                    break
        
        segments.append(sent_text)
    
    # æ–‡è„ˆåˆ†æï¼ˆéš£æ¥ã™ã‚‹æ–‡ã®é–¢ä¿‚ã‚’è€ƒæ…®ï¼‰
    # ä¾‹ï¼šã€Œç§ã¯è€ƒãˆã¾ã—ãŸã€ã®å¾Œã«ç¶šãæ–‡ã¯ã€ã‚¢ã‚¤ãƒ‡ã‚¢ã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„
    result = []
    idea_context = False
    
    for i, segment in enumerate(segments):
        if i > 0 and idea_context and not (segment.startswith("[") or segment.startswith("ï¼ˆ") or segment.startswith("ã€ˆ")):
            # å‰ã®æ–‡ãŒã‚¢ã‚¤ãƒ‡ã‚¢æ–‡è„ˆã§ã€ç¾åœ¨ã®æ–‡ã«ãƒ–ãƒ©ã‚±ãƒƒãƒˆãŒãªã„å ´åˆ
            segment = f"ã€ˆ{segment}ã€‰"
        
        # ã‚¢ã‚¤ãƒ‡ã‚¢æ–‡è„ˆã®æ›´æ–°
        idea_context = any(re.search(pattern, segment) for pattern in [r"è€ƒãˆ", r"æ€ã„", r"ã‚¢ã‚¤ãƒ‡ã‚¢", r"ææ¡ˆ"])
        
        result.append(segment)
    
    return "".join(result)

def create_matrix_visualization(df):
    """ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ã‚’ä½œæˆ"""
    if 'åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹' not in df.columns:
        return None
    
    # ç™ºè¨€ã‚’ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥ã«åˆ†è§£
    matrix_data = []
    for idx, row in df.iterrows():
        segments = decompose_utterance_by_brackets(row['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'])
        
        for bracket_type, content_list in segments.items():
            for content in content_list:
                matrix_data.append({
                    'ç™ºè¨€ç•ªå·': row['ç™ºè¨€ç•ªå·'],
                    'ç™ºè¨€è€…': row['ç™ºè¨€è€…'],
                    'ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡': bracket_type,
                    'å†…å®¹': content,
                    'ç™ºè¨€é †åº': idx
                })
    
    if not matrix_data:
        return None
    
    matrix_df = pd.DataFrame(matrix_data)
    
    # ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆï¼ˆç™ºè¨€ã”ã¨ã®å„ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡ã®æœ‰ç„¡ï¼‰
    pivot_df = matrix_df.groupby(['ç™ºè¨€é †åº', 'ç™ºè¨€ç•ªå·', 'ç™ºè¨€è€…', 'ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡']).size().reset_index(name='count')
    pivot_table = pivot_df.pivot_table(
        index=['ç™ºè¨€é †åº', 'ç™ºè¨€ç•ªå·', 'ç™ºè¨€è€…'], 
        columns='ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡', 
        values='count', 
        fill_value=0
    )
    
    # ã‚«ãƒ©ãƒ ã®é †åºã‚’æŒ‡å®š
    column_order = ['ä¾‹ç¤º', 'æ¦‚å¿µ', 'æ§‹æƒ³', 'ãã®ä»–']
    existing_columns = [col for col in column_order if col in pivot_table.columns]
    pivot_table = pivot_table[existing_columns]
    
    return pivot_table, matrix_df

def plot_interactive_matrix(pivot_table, matrix_df, selected_speakers=None):
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ã‚’ä½œæˆ"""
    if pivot_table is None or matrix_df is None:
        return None
    
    # ç™ºè¨€è€…ã®è‰²åˆ†ã‘ç”¨ã®ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚’ä½œæˆ
    speakers = pivot_table.index.get_level_values('ç™ºè¨€è€…').unique()
    colors = px.colors.qualitative.Set3[:len(speakers)]
    speaker_colors = dict(zip(speakers, colors))
    
    # é¸æŠã•ã‚ŒãŸç™ºè¨€è€…ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ
    if selected_speakers:
        highlight_mask = pivot_table.index.get_level_values('ç™ºè¨€è€…').isin(selected_speakers)
    else:
        highlight_mask = [True] * len(pivot_table)
    
    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
    z_data = pivot_table.values
    y_labels = [f"ç™ºè¨€{row[1]} ({row[2]})" for row in pivot_table.index]
    x_labels = pivot_table.columns.tolist()
    
    # ç™ºè¨€è€…åˆ¥ã®è‰²æƒ…å ±ã‚’æº–å‚™
    speaker_info = [pivot_table.index[i][2] for i in range(len(pivot_table))]
    
    # ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã‚’ä½œæˆ
    fig = go.Figure()
    
    # å„ç™ºè¨€è€…ã”ã¨ã«ç•°ãªã‚‹è‰²ã§ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ä½œæˆ
    for speaker in speakers:
        speaker_mask = [info == speaker for info in speaker_info]
        speaker_indices = [i for i, mask in enumerate(speaker_mask) if mask]
        
        if not speaker_indices:
            continue
        
        # é¸æŠã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ã§é€æ˜åº¦ã‚’èª¿æ•´
        opacity = 1.0 if not selected_speakers or speaker in selected_speakers else 0.3
        
        # å„ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡ã”ã¨ã«æ•£å¸ƒå›³ã‚’ä½œæˆ
        for j, bracket_type in enumerate(x_labels):
            for i in speaker_indices:
                value = z_data[i, j]
                if value > 0:
                    fig.add_trace(go.Scatter(
                        x=[j],
                        y=[i],
                        mode='markers',
                        marker=dict(
                            size=max(10, value * 20),  # å€¤ã«å¿œã˜ã¦ã‚µã‚¤ã‚ºã‚’èª¿æ•´
                            color=speaker_colors[speaker],
                            opacity=opacity,
                            line=dict(width=2, color='black' if speaker in (selected_speakers or []) else 'gray')
                        ),
                        name=speaker,
                        showlegend=speaker_indices[0] == i and j == 0,  # æœ€åˆã®ç‚¹ã®ã¿å‡¡ä¾‹ã«è¡¨ç¤º
                        hovertemplate=f"<b>{y_labels[i]}</b><br>" +
                                    f"ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡: {bracket_type}<br>" +
                                    f"å‡ºç¾å›æ•°: {value}<br>" +
                                    "<extra></extra>"
                    ))
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
    fig.update_layout(
        title="ç™ºè¨€å†…å®¹ã®ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥ãƒãƒˆãƒªã‚¯ã‚¹",
        xaxis=dict(
            title="ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡",
            tickmode='array',
            tickvals=list(range(len(x_labels))),
            ticktext=x_labels,
            side='top'
        ),
        yaxis=dict(
            title="ç™ºè¨€ï¼ˆæ™‚ç³»åˆ—é †ï¼‰",
            tickmode='array',
            tickvals=list(range(len(y_labels))),
            ticktext=y_labels,
            autorange='reversed'  # ä¸Šã‹ã‚‰ä¸‹ã¸æ™‚ç³»åˆ—é †
        ),
        height=max(600, len(y_labels) * 25),
        width=800,
        showlegend=True,
        legend=dict(
            orientation="v",
            yanchor="top",
            y=1,
            xanchor="left",
            x=1.02
        )
    )
    
    return fig

def process_csv(df):
    """CSVãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã€ç™ºè¨€å†…å®¹ã«ãƒ–ãƒ©ã‚±ãƒƒãƒˆã‚’ä»˜ã‘ã‚‹"""
    if 'ç™ºè¨€å†…å®¹' not in df.columns:
        st.error("CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã€Œç™ºè¨€å†…å®¹ã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None
    
    # ç™ºè¨€å†…å®¹ã‚’åˆ†æ
    df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] = df['ç™ºè¨€å†…å®¹'].apply(analyze_text_with_context)
    
    return df

def get_csv_download_link(df, filename="analyzed_data.csv"):
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’CSVã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ"""
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">åˆ†æçµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
    return href

def get_dict_download_link(dict_data, filename="concept_dictionary.txt"):
    """æ¦‚å¿µè¾æ›¸ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ"""
    content = ""
    for category, terms in dict_data.items():
        content += f"[{category}]\n"
        # 10å€‹ã”ã¨ã«æ”¹è¡Œã—ã¦è¦‹ã‚„ã™ãã™ã‚‹
        for i in range(0, len(terms), 10):
            content += ", ".join(terms[i:i+10]) + "\n"
        content += "\n"
    
    b64 = base64.b64encode(content.encode()).decode()
    href = f'<a href="data:file/txt;base64,{b64}" download="{filename}">æ¦‚å¿µè¾æ›¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
    return href

def get_pattern_download_link(filename="patterns.txt"):
    """ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ"""
    content = "# å…·ä½“ä¾‹ãƒ‘ã‚¿ãƒ¼ãƒ³\n"
    for pattern in example_patterns:
        content += pattern + "\n"
    
    content += "\n# ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ»æ€ã„ãƒ»æ§‹æƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³\n"
    for pattern in idea_patterns:
        content += pattern + "\n"
    
    b64 = base64.b64encode(content.encode()).decode()
    href = f'<a href="data:file/txt;base64,{b64}" download="{filename}">ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®šã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
    return href

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š
st.sidebar.header("è¨­å®š")

# æ¦‚å¿µè¾æ›¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
st.sidebar.subheader("æ¦‚å¿µè¾æ›¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
dict_file = st.sidebar.file_uploader("æ¦‚å¿µè¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["txt"])

if dict_file is not None:
    try:
        dict_content = dict_file.getvalue().decode("utf-8")
        uploaded_dict = parse_concept_dict_file(dict_content)
        if uploaded_dict:
            concept_dict = uploaded_dict
            st.sidebar.success("æ¦‚å¿µè¾æ›¸ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
        else:
            st.sidebar.warning("æœ‰åŠ¹ãªæ¦‚å¿µè¾æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¾æ›¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    except Exception as e:
        st.sidebar.error(f"è¾æ›¸ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.sidebar.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¾æ›¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

# æ¦‚å¿µè¾æ›¸ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ã‚’è¡¨ç¤º
st.sidebar.subheader("æ¦‚å¿µè¾æ›¸ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹")
dict_format_example = """
# æ¦‚å¿µè¾æ›¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹
[æ•™ç§‘ãƒ»å˜å…ƒãƒ»æˆæ¥­æ¦‚å¿µ]
æ•°å­¦, ç®—æ•°, å›½èª, ç†ç§‘, ç¤¾ä¼š
æ–¹ç¨‹å¼, é–¢æ•°, å›³å½¢, ç¢ºç‡, çµ±è¨ˆ

[ç¤¾ä¼šçš„æ¦‚å¿µ]
æ°‘ä¸»ä¸»ç¾©, äººæ¨©, ç’°å¢ƒ, æŒç¶šå¯èƒ½æ€§
å¤šæ§˜æ€§, å…¬æ­£, å¹³ç­‰, è‡ªç”±, è²¬ä»»

# ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã¯#ã§å§‹ã‚ã¾ã™
"""
st.sidebar.code(dict_format_example, language="text")

# ç¾åœ¨ã®æ¦‚å¿µè¾æ›¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
if st.sidebar.button("ç¾åœ¨ã®æ¦‚å¿µè¾æ›¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
    st.sidebar.markdown(get_dict_download_link(concept_dict), unsafe_allow_html=True)

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
st.sidebar.subheader("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å½¢å¼")
sample_data = pd.DataFrame({
    'ç™ºè¨€ç•ªå·': [1, 2, 3, 4, 5, 6, 7, 8],
    'ç™ºè¨€è€…': ['æ•™å¸«', 'ç”Ÿå¾’A', 'ç”Ÿå¾’B', 'ç”Ÿå¾’C', 'æ•™å¸«', 'ç”Ÿå¾’A', 'ç”Ÿå¾’D', 'æ•™å¸«'],
    'ç™ºè¨€å†…å®¹': [
        'ä»Šæ—¥ã¯ä¸‰è§’å½¢ã®é¢ç©ã«ã¤ã„ã¦å­¦ã³ã¾ã—ã‚‡ã†ã€‚',
        'ä¾‹ãˆã°ã€ã“ã®å›³å½¢ã®é¢ç©ã¯ã©ã†ã‚„ã£ã¦æ±‚ã‚ã¾ã™ã‹ï¼Ÿ',
        'åº•è¾ºÃ—é«˜ã•Ã·2ã ã¨æ€ã„ã¾ã™ã€‚',
        'æ˜¨æ—¥ã€ãŠçˆ¶ã•ã‚“ã¨ä¸€ç·’ã«å…¬åœ’ã§ä¸‰è§’å½¢ã®çœ‹æ¿ã‚’è¦‹ã¾ã—ãŸã€‚',
        'ã¿ãªã•ã‚“ã®è€ƒãˆã‚’èã‹ã›ã¦ãã ã•ã„ã€‚',
        'ç§ã¯ã€ã‚‚ã£ã¨ç°¡å˜ãªæ–¹æ³•ãŒã‚ã‚‹ã¨æ€ã„ã¾ã™ã€‚',
        'æ•°å­¦ã¯é¢ç™½ã„ã§ã™ã­ã€‚',
        'ãã‚Œã§ã¯æ¬¡ã®å•é¡Œã«é€²ã¿ã¾ã—ã‚‡ã†ã€‚'
    ]
})
st.sidebar.dataframe(sample_data)

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
use_sample = st.checkbox("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨")

# åˆ†æçµæœã®çµ±è¨ˆ
def show_analysis_stats(df):
    if 'analyzed' not in st.session_state:
        st.session_state.analyzed = True
        
        total_utterances = len(df)
        example_count = sum(1 for text in df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if '[' in text)
        concept_count = sum(1 for text in df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if 'ï¼ˆ' in text)
        idea_count = sum(1 for text in df['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'] if 'ã€ˆ' in text)
        
        st.subheader("åˆ†æçµ±è¨ˆ")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ç·ç™ºè¨€æ•°", total_utterances)
        with col2:
            st.metric("å…·ä½“ä¾‹ [ã€€]", example_count, f"{example_count/total_utterances:.1%}")
        with col3:
            st.metric("æ¦‚å¿µ ï¼ˆã€€ï¼‰", concept_count, f"{concept_count/total_utterances:.1%}")
        with col4:
            st.metric("ã‚¢ã‚¤ãƒ‡ã‚¢ ã€ˆã€€ã€‰", idea_count, f"{idea_count/total_utterances:.1%}")

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
if uploaded_file is not None:
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    try:
        df = pd.read_csv(uploaded_file)
        st.subheader("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿")
        st.dataframe(df)
        
        analyzed_df = process_csv(df)
        if analyzed_df is not None:
            st.subheader("åˆ†æçµæœ")
            st.dataframe(analyzed_df)
            st.markdown(get_csv_download_link(analyzed_df), unsafe_allow_html=True)
            
            # åˆ†æçµ±è¨ˆã‚’è¡¨ç¤º
            show_analysis_stats(analyzed_df)
            
            # ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–
            st.subheader("ğŸ“Š ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–")
            
            # ç™ºè¨€è€…é¸æŠæ©Ÿèƒ½
            if 'ç™ºè¨€è€…' in analyzed_df.columns:
                all_speakers = analyzed_df['ç™ºè¨€è€…'].unique().tolist()
                selected_speakers = st.multiselect(
                    "ãƒã‚¤ãƒ©ã‚¤ãƒˆã™ã‚‹ç™ºè¨€è€…ã‚’é¸æŠï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                    options=all_speakers,
                    default=None,
                    help="é¸æŠã—ãŸç™ºè¨€è€…ã®ç™ºè¨€ãŒãƒã‚¤ãƒ©ã‚¤ãƒˆã•ã‚Œã¾ã™ã€‚ä½•ã‚‚é¸æŠã—ãªã„å ´åˆã¯å…¨ã¦ã®ç™ºè¨€è€…ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
                )
                
                if not selected_speakers:
                    selected_speakers = None
            else:
                selected_speakers = None
            
            # ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ã‚’ä½œæˆ
            pivot_table, matrix_df = create_matrix_visualization(analyzed_df)
            
            if pivot_table is not None:
                # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒãƒˆãƒªã‚¯ã‚¹å›³ã‚’è¡¨ç¤º
                matrix_fig = plot_interactive_matrix(pivot_table, matrix_df, selected_speakers)
                if matrix_fig:
                    st.plotly_chart(matrix_fig, use_container_width=True)
                
                # ãƒãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°è¡¨ç¤º
                with st.expander("ãƒãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°"):
                    st.subheader("ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥ã®ç™ºè¨€åˆ†è§£")
                    
                    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½
                    if selected_speakers:
                        filtered_matrix_df = matrix_df[matrix_df['ç™ºè¨€è€…'].isin(selected_speakers)]
                    else:
                        filtered_matrix_df = matrix_df
                    
                    # ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    bracket_filter = st.selectbox(
                        "ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°",
                        options=['å…¨ã¦'] + filtered_matrix_df['ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡'].unique().tolist()
                    )
                    
                    if bracket_filter != 'å…¨ã¦':
                        filtered_matrix_df = filtered_matrix_df[filtered_matrix_df['ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡'] == bracket_filter]
                    
                    st.dataframe(filtered_matrix_df)
                    
                    # çµ±è¨ˆæƒ…å ±
                    st.subheader("ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥çµ±è¨ˆ")
                    bracket_stats = filtered_matrix_df.groupby('ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡').size().reset_index(name='å‡ºç¾å›æ•°')
                    st.bar_chart(bracket_stats.set_index('ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡'))
            else:
                st.warning("ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            
            # è©³ç´°ãªåˆ†æçµæœã®è¡¨ç¤º
            st.subheader("ç™ºè¨€å†…å®¹ã®è©³ç´°åˆ†æ")
            for idx, row in analyzed_df.iterrows():
                # é¸æŠã•ã‚ŒãŸç™ºè¨€è€…ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ
                is_highlighted = selected_speakers is None or row['ç™ºè¨€è€…'] in selected_speakers
                
                with st.expander(f"{'ğŸ”¸' if is_highlighted else 'âšª'} ç™ºè¨€ {row['ç™ºè¨€ç•ªå·']} - {row['ç™ºè¨€è€…']}"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("**å…ƒã®ç™ºè¨€å†…å®¹:**")
                        st.write(row['ç™ºè¨€å†…å®¹'])
                    with col2:
                        st.markdown("**åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹:**")
                        st.write(row['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'])
                    
                    # ãƒ–ãƒ©ã‚±ãƒƒãƒˆåˆ†è§£ã®è¡¨ç¤º
                    segments = decompose_utterance_by_brackets(row['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'])
                    st.markdown("**ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥åˆ†è§£:**")
                    for bracket_type, content_list in segments.items():
                        if content_list:
                            st.markdown(f"- **{bracket_type}**: {', '.join(content_list)}")
                            
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

elif use_sample:
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
    st.subheader("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿")
    st.dataframe(sample_data)
    
    analyzed_df = process_csv(sample_data)
    if analyzed_df is not None:
        st.subheader("åˆ†æçµæœ")
        st.dataframe(analyzed_df)
        st.markdown(get_csv_download_link(analyzed_df, "sample_analyzed_data.csv"), unsafe_allow_html=True)
        
        # åˆ†æçµ±è¨ˆã‚’è¡¨ç¤º
        show_analysis_stats(analyzed_df)
        
        # ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–
        st.subheader("ğŸ“Š ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–")
        
        # ç™ºè¨€è€…é¸æŠæ©Ÿèƒ½
        if 'ç™ºè¨€è€…' in analyzed_df.columns:
            all_speakers = analyzed_df['ç™ºè¨€è€…'].unique().tolist()
            selected_speakers = st.multiselect(
                "ãƒã‚¤ãƒ©ã‚¤ãƒˆã™ã‚‹ç™ºè¨€è€…ã‚’é¸æŠï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                options=all_speakers,
                default=None,
                help="é¸æŠã—ãŸç™ºè¨€è€…ã®ç™ºè¨€ãŒãƒã‚¤ãƒ©ã‚¤ãƒˆã•ã‚Œã¾ã™ã€‚ä½•ã‚‚é¸æŠã—ãªã„å ´åˆã¯å…¨ã¦ã®ç™ºè¨€è€…ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
            )
            
            if not selected_speakers:
                selected_speakers = None
        else:
            selected_speakers = None
        
        # ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ã‚’ä½œæˆ
        pivot_table, matrix_df = create_matrix_visualization(analyzed_df)
        
        if pivot_table is not None:
            # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒãƒˆãƒªã‚¯ã‚¹å›³ã‚’è¡¨ç¤º
            matrix_fig = plot_interactive_matrix(pivot_table, matrix_df, selected_speakers)
            if matrix_fig:
                st.plotly_chart(matrix_fig, use_container_width=True)
            
            # ãƒãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°è¡¨ç¤º
            with st.expander("ãƒãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°"):
                st.subheader("ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥ã®ç™ºè¨€åˆ†è§£")
                
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½
                if selected_speakers:
                    filtered_matrix_df = matrix_df[matrix_df['ç™ºè¨€è€…'].isin(selected_speakers)]
                else:
                    filtered_matrix_df = matrix_df
                
                # ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                bracket_filter = st.selectbox(
                    "ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°",
                    options=['å…¨ã¦'] + filtered_matrix_df['ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡'].unique().tolist()
                )
                
                if bracket_filter != 'å…¨ã¦':
                    filtered_matrix_df = filtered_matrix_df[filtered_matrix_df['ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡'] == bracket_filter]
                
                st.dataframe(filtered_matrix_df)
                
                # çµ±è¨ˆæƒ…å ±
                st.subheader("ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥çµ±è¨ˆ")
                bracket_stats = filtered_matrix_df.groupby('ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡').size().reset_index(name='å‡ºç¾å›æ•°')
                st.bar_chart(bracket_stats.set_index('ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡'))
        else:
            st.warning("ãƒãƒˆãƒªã‚¯ã‚¹å¯è¦–åŒ–ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        # è©³ç´°ãªåˆ†æçµæœã®è¡¨ç¤º
        st.subheader("ç™ºè¨€å†…å®¹ã®è©³ç´°åˆ†æ")
        for idx, row in analyzed_df.iterrows():
            # é¸æŠã•ã‚ŒãŸç™ºè¨€è€…ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ
            is_highlighted = selected_speakers is None or row['ç™ºè¨€è€…'] in selected_speakers
            
            with st.expander(f"{'ğŸ”¸' if is_highlighted else 'âšª'} ç™ºè¨€ {row['ç™ºè¨€ç•ªå·']} - {row['ç™ºè¨€è€…']}"):
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**å…ƒã®ç™ºè¨€å†…å®¹:**")
                    st.write(row['ç™ºè¨€å†…å®¹'])
                with col2:
                    st.markdown("**åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹:**")
                    st.write(row['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'])
                
                # ãƒ–ãƒ©ã‚±ãƒƒãƒˆåˆ†è§£ã®è¡¨ç¤º
                segments = decompose_utterance_by_brackets(row['åˆ†ææ¸ˆã¿ç™ºè¨€å†…å®¹'])
                st.markdown("**ãƒ–ãƒ©ã‚±ãƒƒãƒˆç¨®é¡åˆ¥åˆ†è§£:**")
                for bracket_type, content_list in segments.items():
                    if content_list:
                        st.markdown(f"- **{bracket_type}**: {', '.join(content_list)}")
else:
    st.info("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
